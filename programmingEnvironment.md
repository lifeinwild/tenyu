# 概要
まず思想とは「世界はこうあるべきだ」というような主張であったり、何か普遍的なアイデアや価値観を説くものです。
もし世界が最も合理的な技術や概念を採用して正しく成長していくと信じるなら、正しい思想を考えれば未来が分かります。

それで、これは私がTenyuプロジェクトのソフトウェア構成（どの言語、フレームワークを使うか等）の判断をする時に、あらゆる潜在的な可能性をも考慮して最も優れた判断をしようとして考えた諸々の着眼点や解釈、可能性などです。
「世界はこうあるべきだからこの技術はこう変わるはずで、ならばこの技術を採用するのが正しい」というような論理でソフトウェア構成を決めました。
その他雑多なメモも含まれます。

例えば、**新しいコンピューターやOSの出現を促すために世界的にさらに[クロスプラットフォームを追求すべき](#バーチャルプラットフォーム_語の追加_整理)だ**という考えが強くあり、この文書はその観点が強く出ています。特に重要なアイデアは[fat_java_案](#fat_java_案)または[実行時依存性解決](#実行時依存性解決_案)です。

# License
この文書はTenyuLicenseで公開されます。
用途制限：本ライセンスはp2pソフトウェアまたは創作活動のプラットフォームを作成する目的ではない場合にのみ適用される。

# 目次
- [バーチャルプラットフォーム_語の追加_整理](#バーチャルプラットフォーム_語の追加_整理)
- [バーチャルプラットフォームなソフトウェアのためのランタイムが持つべき特徴_案](#バーチャルプラットフォームなソフトウェアのためのランタイムが持つべき特徴_案)
- [バーチャルプラットフォームなソフトウェアが充実した場合にもたらされるもの](#バーチャルプラットフォームなソフトウェアが充実した場合にもたらされるもの)
- [バーチャルプラットフォームなソフトウェアの増加を促すもの](#バーチャルプラットフォームなソフトウェアの増加を促すもの)
- [ソースコードとバイナリ](#ソースコードとバイナリ)
- [JITの強み](#JITの強み)
- [仮想環境の強み_解釈](#仮想環境の強み_解釈)
- [仮想環境言語とシステムプログラミング言語_案](#仮想環境言語とシステムプログラミング言語_案)
- [fat_java_案](#fat_java_案)
- [JNI用実行時コンパイル_案](#JNI用実行時コンパイル_案)
- [C言語は代替されるか_比較_考察](#C言語は代替されるか_比較_考察)
- [言語とは何か_解釈](#言語とは何か_解釈)
- [何が言語の趨勢を決めるか_期待説_解釈](#何が言語の趨勢を決めるか_期待説_解釈)
- [各言語への一般的期待_解釈](#各言語への一般的期待_解釈)
- [何が言語の趨勢を決めるか_歴史説_解釈](#何が言語の趨勢を決めるか_歴史説_解釈)
- [インタプリタ_解釈](#インタプリタ_解釈)
- [WebAssemblyとJVMが今後衝突する可能性_メモ](#WebAssemblyとJVMが今後衝突する可能性_メモ)
- [仮想デスクトップによるreproducible_builds証明_案](#仮想デスクトップによるreproducible_builds証明_案)
- [自己完結型の否定_批判](#自己完結型の否定_批判)
- [Java8_OS側JDKの必要性_解釈](#Java8_OS側JDKの必要性_解釈)
- [kotlinとjava_メモ](#kotlinとjava_メモ)
- [Glb](#Glb)
- [Glbはオブジェクトであるべきか_考察](#Glbはオブジェクトであるべきか_考察)
- [Glbに依存したクラスを他プロジェクトから使う_メモ](#Glbに依存したクラスを他プロジェクトから使う_メモ)
- [最高のプログラミング言語は_考察_案_解釈](#最高のプログラミング言語は_考察_案_解釈)
- [C言語の特徴_解釈](#C言語の特徴_解釈)
- [GraalVM_メモ](#GraalVM_メモ)
- [WebAssembly_HTML5_解釈](#WebAssembly_HTML5_解釈)
- [Web_解釈](#Web_解釈)
- [実行時依存性解決_案](#実行時依存性解決_案)
- [Jigsaw_解釈](#Jigsaw_解釈)
- [世界的なソースコード検索システム_案](#世界的なソースコード検索システム_案)
- [私が空想する少し未来の理想的なプログラミング環境_案](#私が空想する少し未来の理想的なプログラミング環境_案)
- [Lombokの使用範囲_考察_解釈](#Lombokの使用範囲_考察_解釈)
- [プログラミングの本質的進歩とは_解釈](#プログラミングの本質的進歩とは_解釈)
- [汎用プログラミング言語でビルド処理を書く_メモ](#汎用プログラミング言語でビルド処理を書く_メモ)
- [プログラミング言語によるビルド処理が必要になった場面_経験](#プログラミング言語によるビルド処理が必要になった場面_経験)
- [P2P_PKI_メモ](#P2P_PKI_メモ)
- [OOPとは_説明_解釈](#OOPとは_説明_解釈)
- [継承より構成_比較_考察](#継承より構成_比較_考察)
- [問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説](#問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説)
- [構成的多重継承_素案](#構成的多重継承_素案)
- [構成を言語仕様でサポートする_parent_素案](#構成を言語仕様でサポートする_parent_素案)
- [Neckless言語_解釈_説明](#Neckless言語_解釈_説明)
- [リリース番号_案](#リリース番号_案)
- [ソースコード公開確認API_案](#ソースコード公開確認API_案)
- [セーフランチャー_案](#セーフランチャー_案)
- [3Dゲームにおける演出用サブ物理空間_案](#3Dゲームにおける演出用サブ物理空間_案)
- [オンラインゲームの物理演算_案](#オンラインゲームの物理演算_案)
- [ソフトウェアプロジェクトの死_問題](#ソフトウェアプロジェクトの死_問題)
- [ネットにアクセスするコンピューターの水準を底上げする_問題_解釈](#ネットにアクセスするコンピューターの水準を底上げする_問題_解釈)
- [創発的なソフトウェア_解釈_案_思想](#創発的なソフトウェア_解釈_案_思想)
- [自由ソフトウェア_コピーレフト_オープンソース_TenyuLicense_比較](#自由ソフトウェア_コピーレフト_オープンソース_TenyuLicense_比較)
- [GNUとLinuxとUnix_解釈](#GNUとLinuxとUnix_解釈)
- [リベラル_思想](#リベラル_思想)
- [staticを使うべき場面_経験](#staticを使うべき場面_経験)
- [NVMe_SSD_予想](#NVMe_SSD_予想)
- [デシリアライズ用コンストラクタ_案](#デシリアライズ用コンストラクタ_案)
- [OSがLLVM標準搭載_案](#OSがLLVM標準搭載_案)
- [CPU命令セットの爆発的多様化によるセキュリティの改善_予想](#CPU命令セットの爆発的多様化によるセキュリティの改善_予想)
- [OSは多様化するか_予想](#OSは多様化するか_予想)
- [LLVMとJDK_考察_案_メモ](#LLVMとJDK_考察_案_メモ)
- [プログラムの統一_プログラマーの均質化_案](#プログラムの統一_プログラマーの均質化_案)
- [Moduleとアドイン](#Moduleとアドイン)
- [１プロセスで多数のJavaアプリを動かす_案](#１プロセスで多数のJavaアプリを動かす_案)
- [Javaの複雑化_愚痴](#Javaの複雑化_愚痴)
- [プロジェクト間違い_問題](#プロジェクト間違い_問題)
- [Tenyutalk_案_独自ソフト](#Tenyutalk_案_独自ソフト)
- [IPアドレスからレイテンシを予測する](#IPアドレスからレイテンシを予測する)
- [Tenyu基盤ソフトウェアのモデルクラス](#Tenyu基盤ソフトウェアのモデルクラス)

# バーチャルプラットフォーム_語の追加_整理
まず、クロスプラットフォームは**現在存在する複数のプラットフォームで動作する**というだけで条件を満たします。
そして**バーチャルプラットフォームは仮想環境にのみ依存しているという条件を指し**、その仮想環境さえ提供されればどんな環境でも動作するので、その意味で**未知の**プラットフォームでも動作させやすい性質があります。

クロスプラットフォームなソフトウェアは内部にネイティブコードを含んでいて未知の環境で動作させれない可能性があります。環境毎のネイティブコードを実行時環境に応じて切り替えて使用している場合があります。それでもクロスプラットフォームに該当します。

バーチャルプラットフォームという語はpure javaとほぼ同じ意味ですが、とはいえjava以外でもバーチャルプラットフォームなソフトウェアはありうるので、pure javaという語はjavaコードにしか使えないのでバーチャルプラットフォームという語を使っています。

バーチャルプラットフォームなソフトウェアはコンピューターやOSの変化に強く、様々なOSの元で実行されるP2Pプラットフォームに適します。
そして**ハードウェアやOSの変化を促します**。

誰かが新しいプラットフォームを作るとします。例えば新しいCPU命令セットを。
新しいプラットフォームはソフトウェア資産において古いプラットフォームに負ける可能性が高いですが、もしバーチャルプラットフォームなソフトウェア資産が多数あれば、その仮想環境のランタイムさえ実装すればそれらを全て活用できます。

javaはある程度そのような事を実現しうるプラットフォームですが、一部のjavaライブラリはネイティブコードを含んでいて新しいプラットフォームがJDKを実装しても動作しません。
典型的にはそのようなソフトウェアはwindows, linux, macなどのメジャー環境毎にネイティブコードを持ち、環境に応じて使い分けています。
後述する[fat java案](#fat_java_案)はそのネイティブコード同梱問題を解決します。

クロスプラットフォームと呼ばれるものの詳細な分類
- バイナリレベルの限定的な互換性。ネイティブコードを含むJVMライブラリなど。多くの環境に対応していて、未知の環境に対応していない。
- バイナリレベルの完全な互換性。pure javaなソフトウェアなど。これがバーチャルプラットフォーム。JDKさえ実装されれば完全に動作するので未知の環境にも対応している。
- ソースコードレベルの限定的な互換性。ソースコードを様々な環境に向けてビルドできる。C言語のifdefを使って様々な環境に対応するなど。
- ソースコードレベルの完全な互換性。コンパイラ等が実装されればあらゆる環境でビルドできる。クロスプラットフォームなマナーで書かれたC++プログラムなど。

# バーチャルプラットフォームなソフトウェアのためのランタイムが持つべき特徴_案
ここでランタイムは仮想環境を実装したソフトウェア。
- 中間コードでアプリをバイナリ互換にする。CPUやOSの変化からソフトウェア資産を守る。
- 中間コードからLLVM IRへのJITを持つ。
- 第三者による実装がライセンス上可能である事。新しいプラットフォームを作る人がそのプラットフォーム版のランタイムを自由に作成して配布できる事。
- 可能な限り優れた移植性。新しいプラットフォーム向けに移植しやすい事。
- 標準APIをハードウェアアクセラレーションする機構を備える。実行時環境がハードウェアアクセラレーションを提供していればそれを利用する。
- 標準APIの強化([fat java案](#fat_java_案))やネイティブコード用ソースコードを実行時コンパイルする(JNI用実行時コンパイル案)で全アプリを完全にバーチャルプラットフォームにする。
- p2pを主な領域として想定する。バイナリ互換が重要だから。dockerやソースコードレベルのクロスプラットフォームと比較した時、バイナリ互換の主張点はその領域しかない。p2pプラットフォームにアプリストアが構築され、バイナリ互換のプログラムが配布されるという事。

# バーチャルプラットフォームなソフトウェアが充実した場合にもたらされるもの
- ISAの多様化。RISC-V等
- OSの多様化または移行

# バーチャルプラットフォームなソフトウェアの増加を促すもの
- アドインを扱うP2Pプラットフォーム
- WWWを代替するプラットフォーム

# ソースコードとバイナリ
誰かが別のOSに移行したいとします。現在使っているアプリがバイナリ互換であれば簡単に移行できます。
バイナリ互換ではなくソースコード互換のアプリもあります。
様々なプラットフォームに向けてビルド可能なソースコードからビルドされたアプリです。
しかしソースコード互換のアプリはエンドユーザーが新しいOSに移行するのを阻害します。
いちいちビルドしなおすか、誰かがビルドしたものを再インストールする必要があるからです。
バイナリ互換のアプリはプラットフォームの革新を阻害しないという点で最も創発的だと言えます。

さらにクラウドやP2Pにおいてバイナリ互換のアプリは適しています。
P2Pでは例えば誰もがネットワークに自作のアプレットを送信できるような仕組みが考えられます。
セキュリティは権限管理で対応します。

# JITの強み
**ハードウェアに新機能の実装を促せる可能性がある**。32bitから64bitへの移行の時、C++アプリよりJavaアプリの方が高速な事例があったようです。JavaはJITを更新するだけでCPUの新機能を活用できるのに対して、C++アプリはアプリ毎に再ビルドと再インストールが必要です。
つまり中間コードとJITというアイデアはこの点でより創発的だと言えます。

# 仮想環境の強み_解釈
仮想環境の例はJDKや.NET Coreです。
一般にそのようなものはプロセス仮想機械と呼ばれていますが、私はアプリ側から見た印象で仮想環境と呼んでいます。極論すれば仮想環境はプロセス概念と関連付ける必要性がありません。極論ですがもしかしたら1プロセスの中に多数の仮想環境が作られるかもしれないし、多数のプロセスが協調して1つの仮想環境を作るかもしれないし、仮想環境がハードウェア実装されたり、カーネルの概念設計が全く変わってプロセスという概念が用いられなくなるかもしれませんが、どうなろうとも仮想環境のみに依存したソフトウェア資産は仮想環境が実現されたなら動作すべきです。

良く言われる仮想環境の強みは実行ファイルのバイナリ互換です。
もう1つはサンドボックス適性です。機械語プログラムでサンドボックスをやるにはVMware等システム仮想機械が必要です。

私は他にも重要な特徴がある事に気付きました。**仮想環境はアプレット適性が高い**。
C++等のネイティブコンパイル言語と比較した場合、**仮想環境言語は任意の人が作ったアプレットやアドインを省メモリかつ高速に実行できます**。
アプレットとはアプリ上で実行されるアプリです。アプレットの例はJavaアプレットやFlashやwasmです。
Webブラウザの考察の方でも書きましたが、例えば**もしWebブラウザがJavaベースで作られていたらJavaアプレットの起動は高速だったはず**です。WebブラウザがC++ベースで作られている時点でJavaアプレットに限らずWebページ上で実行されるプログラムのために仮想環境を起動する必要があります。その仮想環境が高機能であるほど起動時間が問題になります。**WebブラウザをC++で作るという判断がアプレットに適していません**。ホストアプリとアプレットが同じランタイム上で実行される方が省メモリになります。
任意の人がプログラムを加えれるプログラム、つまりアプレットやアドインに対応したアプリは仮想環境言語で作られるべきです。

アプレットからホストアプリに自由にアクセスさせないようにする必要があります。
ホストアプリが仮想環境言語で作られていた場合アプレットがその内容にアクセスしやすくなりセキュリティ上のリスクがあります。例えばアプレットからホストアプリのグローバル状態にアクセスできるかもしれません。
しかしホストアプリは一部の状態や機能をアプレットに提供したいかもしれません。
この点でアクセス可能なパッケージを制限する必要があり、Java9+以降のモジュールか、私が勝手に考えている1プロセス上で多数のJavaアプリを実行する疑似カーネルの仕組みが必要になります。
疑似カーネルの場合、アプレットは疑似RPCでホストアプリとやり取りします。

# 仮想環境言語とシステムプログラミング言語_案
**仮想環境言語とシステムプログラミング言語という組み合わせは究極的にも有力**だと思っています。
仮想環境言語はあらゆる環境で共通の機能を使用できます。例えばJavaはJDKという一種の仮想環境を想定した言語です。
システムプログラミング言語は環境固有機能を使用できたりフリースタンディングできます。例えばCです。
**システムプログラミング言語はコンピュータに対するほぼ完全な制御性を持つ**という特徴から仮想環境の欠点を補える。仮想環境はどの環境でも出来る事しかできません。だから仮想環境は1つシステムプログラミング言語を想定し連携すべきです。
**このアイデアはコンピュータをプログラミングするという問題に対する根本的な解決のフレームワークの一部です**。

# fat_java_案
JDKにAPIを追加しまくれば、それらはネイティブ実装されるので、ユーザーライブラリがネイティブコードを同梱する必要性がほぼなくなるだろうというアイデア。
jvmライブラリでネイティブコードを同梱しているものを広く調査して、JDKにそれらネイティブコードを代替するAPIを実装する。
そのJDKの肥大化によってほぼすべてのjvmライブラリをpure javaにしようというアイデア。
APIはライブラリのを直接持ってくるのではなく、できるだけ汎用的にする。その主な方法はステートレスにする事とフルパラメタライズする事。
"新しいコンピューターアーキテクチャを作る人がJDKさえ実装できればほとんどのJavaアプリが動く"という状況を作るのが理想。

このアイデアの良いところはJava世界でどんなネイティブAPIが必要とされているかが既存のライブラリによって洗い出されている事にある。
性能的にもメリットがあるはずで、JNIでネイティブコードと連携するとオーバーヘッドがあるが、JDKに実装する事でそれを無くせるはず。

ただし[LLVM+JDK](#LLVMとJDK_考察_案_メモ)というアイデアでもpure javaが促進される。性能のためのネイティブコードは使われなくなる可能性がある。

# JNI用実行時コンパイル_案
JNI用のソースコードをJarに含めて実行時コンパイルする事でソースコード記述時点で存在しない環境にも対応しようというアイデアです。
とはいえ、**JDKが最終的にJNIに期待するのは環境固有機能の使用**だろうと思います。性能目的でのJNI使用は多数実在していますが、JITと[fat java案](#fat_java_案)で解消できるはずだから、最終的には環境固有機能、特に特殊なハードウェア機能の利用がJNIの役割になるはずで、結局JNIを使用するコードはバーチャルプラットフォームにならない可能性が高い。環境固有機能を呼び出すコードはどう努力しようとも**その意味によって環境依存します**。

実行時コンパイルするとして、JNI用のコードをどの言語で書くべきか？

C案。
Cコードをjarに同梱し、JDKにCコンパイラを同梱し、実行時コンパイルする。Javaと相補的という意味ではCの方がC++より合う。学習コストが低い。コンパイル時間が短い。
- Cは静的解析ツールがあるので移植性が無いコードを排除できます。
- [Cコンパイラの普遍性](#C言語の特徴_解釈)
- コンパイル結果はどうせJDKのJITが効かないのでキャッシュしておく。

LLVM案
- [OSがLLVMを標準搭載するという前提](#OSがLLVM標準搭載_案)
- [LLVM IRコンパイラの普遍性](#LLVM_IRコンパイラの普遍性)

JNIコードは環境固有機能を呼び出す場合もあり、その場合どうやっても環境依存する。しかしjarに同梱してソースコードを実行時コンパイルする方が少し変化に強くなる。例えば命令セットの変化に強くなる。

# C言語は代替されるか_比較_考察
Cで書かれたプログラムは脆弱性が多かったり保守性が低いので代替が望まれます。
しかし、Cはあらゆる言語の中で最も膨大かつ基礎的な既存資産を持ち、膨大な実績があります。
さらにCコンパイラの普遍性やコンピューターの完全な制御性からCは最も使用されるシステムプログラミング言語です。

Cの代替が不可能と感じる一方で、他の言語からCへのトランスパイラはアイデアとして優れていると感じます。
何か他の言語を作り、そこからCにトランスパイルできるようにすれば、即座にあらゆる環境でその言語は機械語へコンパイル可能になります。さらに今後出現する未知の環境においてもCコンパイラは恐らく作成されるので、未知の環境でも機械語へコンパイル可能になります。
- Cコードは機械語と単純に対応づくので機械語にコンパイルできるならCコードにトランスパイルできる。
- Cコンパイラの普遍性からCへのトランスパイラは価値が高い。
- 環境非依存のコードを作成し、Cへのトランスパイルのタイミングで環境依存させれる。
- より大規模開発に適した言語仕様を提供できる。

しかし、カーネル等ハードウェアに近い開発では単にCの言語仕様がハードウェアの動作や状態をイメージしやすく優れているという意見があります。
Cは静的解析ツールが多数あるので他の言語が上回るのは簡単では無さそうです。

さらに、LLVMはこのアイデアの上位互換となるものを既に実現しています。
LLVMは様々な言語からCコードや機械語やIRを作成できます。

C++はCを代替するための良い条件を満たしているように思いますが、Cを置き換えていません。
C++の学習コストの高さ、言語仕様の複雑さから生じるプログラマー毎の設計方針の食い違い、そしてCの単純な言語仕様が適している領域がある事が原因だと思います。
詳細なメモリ管理やタイミングなどコンピューターを完全に制御したい場合、抽象化の上では逆にやり辛い。
コンピューターの動作や状態をプログラマーが意識しながらコーディングできること、大人数の開発でも一貫してそのようなコードしか書かれないこと。それらを考慮するとC++よりCの方がハードウェアに近い領域では適している可能性が高い。

ZigはCを代替するか？
恐らく代替しません。
- Cの脆弱性の多さは恐らく静的解析ツールによって大部分解決されます。
- Zigの性能と保守性はCと大差無いだろうと思います。

Nimは微妙にCにもC++にも勝てなくて使用領域が無い。
- NimはGCつきのシステムプログラミング言語ですが、恐らく静的解析ツールが付随したGC無し言語の方がシステムプログラミング言語として優れています。GCは一部の開発では邪魔になります。
- 一貫してCの方がハードウェアの動作をイメージしやすいコードが書かれる。以上からハードウェアに近い領域でCに勝てません。
- 抽象度が高い言語は、CにトランスパイルするよりC++のように直接機械語にコンパイルする方が最適化の余地が大きいので、Cトランスパイラ言語のNimはC++に性能で勝てないだろうと思います。
- Nimは高度かつ複雑な言語仕様によってプログラマーの均質化に失敗しそうです。

それで、Cは代替されるか？私の考えはこうです。
**LLVMによって各種言語からCへのトランスパイルが可能になり、成熟したC++があるし、最新のRustがありますが、いずれもCを置き換えていないという事実がある。そして静的解析ツールがあればCの脆弱性を克服できる事から、今後もCは代替されません**。

# 言語とは何か_解釈
言語は処理系や言語仕様や開発ツールも含み、どの部分もバージョンアップされていく。
それを構成する全部分が更新可能でもそれ自体が存在する。
例えばオブジェクトの全メンバーにセッターがあり更新したとしてもそのオブジェクト自体は変わらず存在し続けているように。
活動の連鎖性みたいなものがそれを捕捉させる。
JavaとかPHPとか言語の名前が意味しているのはそれ。

言語と言語仕様は良く混同されているが区別すべき。
例えば言語という言葉で言語仕様を指して「言語で性能が決まるわけではない」という言説がたまにあるが、ランタイムやコンパイラをも含んで言語と呼ぶべきなので、言語は性能に影響する。
候補となるランタイムやコンパイラが複数ある場合もあるが、それも含めて様々な事を念頭においた文章を書くしかない。

# 何が言語の趨勢を決めるか_期待説_解釈
**エコシステムから言語への期待の発生、言語仕様や処理系がエコシステムからの期待に応えて成長する、他プロジェクトへの期待の伝染と採用の広がり、そのような活動が言語周辺のエコシステムにある**。その活動が繰り返される限り言語は広まる。言語の流行りや廃りはそのような活動によって決まります。

各言語はそのソフトウェアエコシステムから何らかの**期待**を受けています。
Javaエコシステム、PHPエコシステム、Cエコシステムなど、それぞれ言語への期待が違います。
クロスプラットフォームであれ、ライトウェイトであれ、フリースタンディング可能であれ、など。
期待は言語側が自称する特徴や実際に実現されている特徴と必ずしも一致しません。とはいえ人々はバカではないので、期待は概ね実体と一致します。

言語は期待に応じてアップデートされます。そうしなければエコシステムと軋轢が生じます。
新しいプロジェクトが言語を選定する時、必要な特徴を持つ言語を探しますが、完全な確認をせずせいぜい評判や実績を調べるだけです。だから言い換えれば期待が伝染します。
同じ期待を持つプロジェクトがその言語を採用するとその言語のアップデートの方向性が規定されます。

http://readwrite.jp/develop/13680/
>「古いジョークに、エンジニアが今後30年間使われる言語は何かと聞かれて、分からないけどそれでもそれはFortranと呼ばれてるだろう、と答えたというのがある。息の長い言語は、70～80年代にデザインされたものと同じではない。多くの場合、人々は言語から何かを引くことはないが、足すことはある。そうすることで後方互換性は損なわれずに問題が修正されるからだ」

Fortranは非常に古い言語で、科学技術計算の期待に応え続けてきたという事になると思いますが、**時代によって具体的な要求は様々だった**と思います。言語はエコシステムからの期待に応えるためにアップデートされ、変化し続けます。

言語は一部の期待を捨て去る場合があります。
近年のメジャー言語でも後方互換性が捨てられた場合があります。
例えばJava AppletはJava11で廃止されました。これまでいくつものAPIがdeprecatedないし廃止されました。Python 3.0は後方互換性を捨てました。JavaでWebフロントエンドを作っていた人達が居ましたが、もはやJavaにそれを期待する事はできません。つまりJavaはある種の期待を切り捨てたのです。OpenOfficeなどWeb以外でもJavaアプレットを使っていたソフトウェアが存在するようです。
Javaアプレットを使用している人達が多ければ切り捨てられなかったはずです。
つまりその言語が現時点で何を実装しているかよりもその言語にどのような期待が集まっているかが本質です。

DやNimなどたまに言語仕様が優れていると評価されるのに流行しない言語があります。
- **実際のソフトウェアプロジェクト**から期待されていない。言語マニアの注目を集めているだけ。
- 将来のアップデートの方向性や想定する利用者を言語側が宣言していない。
- 既存言語と同じ利用者層に訴えかけている。実績が無い言語は期待を奪えません。新興言語は**独自の期待**を得る事が鍵です。

結局、言語の趨勢を決めるのは**期待**です。PHPという成功例がそれを示しています。

# 各言語への一般的期待_解釈
Javaはクロスプラットフォームという期待を受けています。公式の処理系や言語仕様だけでなく、Java周辺のエコシステムが作るライブラリはクロスプラットフォームである事が多く、そうでないなら明記されるだろうと思えます。
ライブラリの豊富さやJDKの質についても期待されます。恐らくJavaが流行した理由は仮想機械＋中間コード＋JITという構成で高度なクロスプラットフォームを実現するという独自の期待を得た事、そして期待に応え続けた事です。

C言語は**コンピューターの完全な制御**と**そこそこの移植性**と**コンパイラを書きやすい事**を期待されています。

C#は後発言語としてbetter javaであること、MSの構想で良くサポートされたりMSの開発力によって高水準が維持されるだろうと思います。

PHPは手早くウェブサイトを作れる事を期待されていました。PHP: Hypertext Preprocessor この名前はそれが何であるかを示しています。それは当時独自の期待だったと思います。
PHPはいくつかのDBを標準でサポートしています。例えばmysql_query()という関数が定義されていました。それはとてもPHPらしいことで、汎用性を重視するプログラミング言語はそのような事をしません。
PHP対応したレンタルサーバがたくさんあり、誰でも簡単に動的なWEBサイトを作れました。そのようなエコシステムもPHPらしいことです。

JavaScriptはWEBフロントエンドが期待されます。近年ではサーバサイドでも使われます。
ちなみにJSやTSはWebAssemblyによって殺されるか？恐らく殺されない。他の言語のエコシステムはWebフロントエンドのために成長する意欲をほとんど持っていない。しかしC++が進出してくるかもしれません。そもそも私はwasmの行方にまだ懐疑的です。

Python。
業務の細かな場面で使われる利用者数が限定的なアプリがPythonで作られる。
Pythonは機械学習に使われますがそのコアな部分はネイティブコードを含むライブラリで処理します。
**Python+ネイティブコードという多言語連携でPythonのちょっとしたアプリを作る適性と高速な機械学習を組み合わせる**事に利点があるのだろうと思います。例えば、WebスクレイピングとかWebサイトのDBから取得したデータからAIで抽出したデータをサーバに自動登録するあるいは誰かにメールするとか。利用者数や利用頻度が限定的な業務アプリに適している。

Nim。流行っていません。「効率的で表現豊かで美しい言語」。それを語られてもどのプロジェクトがこれを採用すればいいのか分かりません。Nimに欠けているものはターゲット層を明確にする事です。
  
# 何が言語の趨勢を決めるか_歴史説_解釈
いくつかの言語は既存の言語よりスマートにコードを書けるなど言語仕様上の細かなメリットを主張し、既存の言語を代替するために登場しました。例えばkotlinはbetter javaとして登場しました。
しかしそのような言語は多くの場合既存の言語を代替しません。

多くの専門家が新興言語の方が優れていると説明してもなかなか代替は起きません。なぜか？
1. 既存言語もバージョンアップで言語仕様を改良できるから。
2. 細かな改良でいちいち言語を乗り換えていたらキリがないから。
3. 僅かなメリットのために新しい言語を覚えるのが嫌。
4. 抱えているプロジェクトが既存言語で書かれている。

特に2について。エコシステムが軽率な理由で言語を乗り換えるなら小さなエコシステムが乱立する事になりどのエコシステムも十分なソフトウェア資産を持たなくなりライブラリの量やプログラマーの調達に苦労するようになります。だから既存の主流言語が改良されるのを待つという判断は全体利益に適います。  
私はJavaを学び始めた時知り合いのエンジニアからkotlinを進められましたが、それでもJavaを選択しました。新たに言語を学ぶという段階でもより優れた新興言語ではなくJavaを選びました。さらに、Javaを学ぶ前にC#を使った事があり素晴らしい言語だと思いましたがそれでもJavaを選びました。Javaはクロスプラットフォームな実行バイナリを作れるプログラミング環境として標準的で、恐らく歴史的に最初にそのコンセプトに取り組み実現しました。僅かなメリットのためにJava以外へと移るようではエコシステムの安定が得られず全体利益を損ねるのでその態度に疑問を感じたからです。私は歴史的理由からJavaを選択しました。

# インタプリタ_解釈
昔インタプリタがスクリプトを実行時環境で解釈する事でクロスプラットフォーム性が高まるという観点がありましたが、中間コード（Javaバイトコード等）を実行時環境でJITするという方式は上位互換であるように思います。
強いて言えばソースコードを配布する方式は実行時環境でエンドユーザーがソースコードを確認、修正しやすいかもしれませんが、実際そのような動態は生じそうにありません。

# WebAssemblyとJVMが今後衝突する可能性_メモ
- WebAssembly  
    セキュリティ◎  
    性能◎  
    クロスプラットフォーム〇  
    汎用目的△？  
    多言語〇  
    ブラウザではより厳しいセキュリティが要求され、機能は制限されます。  
    セキュリティは計測不能な対象であり見解が分かれます。ブラウザ毎にセキュリティに関する見解が異なる可能性があり、互換性に限界が出る可能性があります。ブラウザ間の互換性問題があるかもしれないという点でクロスプラットフォーム〇に。  
    汎用目的はWASIプロジェクト次第なので？つき。  

- JVM  
    セキュリティ△？  
    性能◎  
    クロスプラットフォーム◎  
    汎用目的◎  
    多言語〇  
    ブラウザのサンドボックスに比べればJVMはリスクがある。  
    しかし、だからこそソースコードを公開するプロジェクトと相性が良い。  
    実行時にリポジトリにアクセスしてソースコードが公開されているかを確認するシステムが確立すればセキュリティ面は改善する可能性がある。後述するセーフランチャーのようなアイデア。  
    JVMはバッファオーバーフローなど不意な脆弱性を生み出してしまうリスクは小さいので、問題となるのは悪意あるコードを排除できるかです。開発者の信用評価をするシステムもJVMにとって重要です。  
    後述しますがシリアライズされたオブジェクトを送受信するシステムがWWWを置き換える可能性があり、  
    Javaはそのようなシステムを記述するのに適した言語の1つです。  

# 仮想デスクトップによるreproducible_builds証明_案
このような機能があればreproducible buildsを証明できそうです。
githubが仮想デスクトップを提供し、開発者がそこでビルド手順を実行し、
その模様を記録し、作成されたバイナリを入れるフォルダがありそれがリリースに置かれる。
その操作の模様と結果をgithub上に表示する。

# 自己完結型の否定_批判
Java9+では自己完結型が推奨されるようです。自己完結型はバイナリ互換性がありません。
https://aoe-tk.hatenablog.com/category/Java
>Java 11ではPublic JREが本当になくなりました

一応Java 11以降でもOS側JDKはありえます。Liberica JDKがJavaFX+MSIインストーラーを提供しています。
しかしLibericaは潜在的な可能性のための最後の配慮であり、現在のJavaでは自己完結型が推奨されているという印象があります。

しかし**自己完結型が主流になりバイナリ互換を失えばJVMを使用している意味がありません**。
**C++とQtのように仮想機械無しでソースコードレベルのクロスプラットフォームを実現した言語がありますが、それに対して自己完結型の主張点は何か？**
GCやバッファオーバーフローが起きにくいといった事を主張してみても、静的解析ツールである程度補えるし、GC強制言語でソースコードレベルのクロスプラットフォームを達成する事も可能です。
JITによる実行時情報の活用があるものの、ほとんどの場合C++の方が高性能です。
要するに**JVM等の仮想機械を採用する理由はバイナリ互換以外無い**。
ネットを検索するとJVMは偉大であるという評価が良く出てきますが、Java9+以降の自己完結型の流れによってその存在意義は揺らいでいます。

現状Java9+はあまり使われていません。多くのプロジェクトがJava8に留まっています。
https://snyk.io/blog/jvm-ecosystem-report-2018/
少し前のデータですが、Java9+全体でJava7未満です。Java8には到底及びません。
こうなっている理由はいくつか考えられます。
・Java9-10が短期サポートしかない。Java11を待っている。
・単に時間が足りてない。いずれJava9+にする。
・Java9+への移行作業が苦痛。自己完結型を求めていない。使用しているライブラリがJigsawに対応していない。
https://qiita.com/kazumura/items/50f041054572ceffe994
＞(B) JPMS(Jigsaw)の否定

Jigsawは自己完結型を推進する仕組みです。

依然Java8が最も多いものの、僅かに減少し、Java11の採用が増えてきています。
https://qiita.com/kazumura/items/46c5b99a9ff422f2eb45

バイナリ互換の放棄はJavaの技術的特徴を失わせます。
しかし、実はJavaの方針にバイナリ互換は入っていません。
https://en.wikipedia.org/wiki/Java_(programming_language)#Principles
portableはソースコードレベルの移植性を意味します。
Javaの基本方針からの逸脱は無い、という事です。
自己完結型はinterpretedかつportableでありながらバイナリ互換を壊します。  
しかし、やはりjvmの存在は実行バイナリのクロスプラットフォーム性を意味するもので、Javaがエコシステムに期待させたものです。  
P2P領域でバイナリ互換のプログラムが必要とされるし、特にアプレットを自由にP2Pネットワークに流すようなシステムがWWWを置き換える可能性があり、Javaは実行ファイルのクロスプラットフォーム性を維持すべきです。

私は、非自己完結型JVMの利点として、[１プロセスで多数のJavaアプリを動かす](#１プロセスで多数のJavaアプリを動かす_案)、さらに[アプレット適性](#仮想環境の強み_解釈)について書きました。

# Java8_OS側JDKの必要性_解釈
https://github.com/corretto/corretto-8/issues/108
私はJava環境がこのようになることを期待しています。
2つのJavaが共存すべきだと思います。OSサイドのJava8JRE+自己完結型の最新JRE。JigsawはJava9+を自己完結型にするのに適している。下位互換性は、OSのJava8JREによって維持されます。自己完結型のアプリケーションは、JREの脆弱性を残す可能性が高くなります。OS側のJREが存在する必要があります。下位互換性のためにはJava8でなければなりません。いくつかの有名なプロジェクトはJava8からJava9+への移行に苦労したり失敗したりしている。私の考えが正しければ、Java8のjreインストーラとアンインストーラは将来永久に必要になると思います。

Java9+は後方互換性を簡単に捨てるようになったと思います。
バイナリ互換のクロスプラットフォームも失いました。

それで私は2つのJavaが併存する事を主張しました。
Liberica JDKがOS側JDKとして適していると思っています。
 
# kotlinとjava_メモ
私はjme3を使う事を考えていて、jme3 sdkはnetbeansベースで、netbeans+kotlinのプラグインはプロジェクトが停止しています。
https://github.com/JetBrains/kotlin-netbeans/issues/122

javaはnull安全がありませんが静的解析ツールで補えます。

# Glb
TenyuはGlbという特殊なクラスを使用しています。  
https://github.com/lifeinwild/tenyu/blob/master/src/main/java/bei7473p5254d69jcuat/tenyu/release1/global/Glb.java  

私のおぼろげな記憶によれば、これは昔某社で見かけたアイデアであり私の発想ではありません。
Glbはプロセスにただ1つのクラスで、グローバル状態を管理し、インスタンスが作られずstaticメンバーで構成され、特殊な仕組みは一切なくとても単純なものです。
グローバル状態への批判は非常に強いのでGlbは批判されそうですが、実際どうだったか。
 - テストは非常にしやすい。セッターでテスト用インスタンスをセットするだけで実行時環境をテスト用にできます。
 テスト用クラスは本番用クラスを継承して一部メンバーをオーバーライドするだけです。
 - Glbはトランザクションが必要な場合があります。
 その領域はSoftware Transaction Memoryと言われているようです。
 ClojureがSTMを実装していますが性能が悪いようです。
 STMは根本的アイデアとして十分に解決されていない。
 - Glbは構文にとって最も素直な方法で扱う事ができます。
 - アプリのあらゆるクラスがGlbに依存する可能性があるので、もし一部のクラスを他のプロジェクトと共有する事を考えた場合、問題になります。後述します。
 - Glb的アイデアを推し進めると階層型オブジェクトという世界観でシステムを捉えれるような気がしてくる。staticメンバーはクラスローダー内で一意になりますが、Glbのstaticメンバーはそのクラスローダー空間を1個のオブジェクトとみなした場合のメンバーである、というような。一般にオブジェクトのメンバー変数がメソッドから可視でありそのクラス内の標準知識であるように、Glbのstaticメンバーはそのクラスローダー空間で可視であり標準知識という事。
 - Glbをデフォルトパッケージに置いて、かつそのstaticインターフェースについて共通規格化すると、Glbに依存したクラスを他プロジェクトで再利用可能になる。しかし現在のJavaの仕様ではデフォルトパッケージに置かれたクラスを他のパッケージでインポートできない。

Glb的アイデアを主張している人が他にいないか探しましたが、こんな記事を見つけました。https://www.ibm.com/developerworks/jp/webservices/library/co-single.html

# Glbはオブジェクトであるべきか_考察
現在の実装では[Glb](#Glb)は純粋にstaticでありインスタンス化されません。
もしGlb自体がオブジェクトだと、Glbの外側のロジックが出現します。
Glbをオブジェクト化する場合、Glbをメソッドの引数に入力しローカル変数として扱う場合が出てきます。
恐らくそれは問題を引き起こします。  
Glbと名付けられたものがLocalになる事は意味的な間違いがあります。

# Glbに依存したクラスを他プロジェクトから使う_メモ
Glbはいくつかsetup系メソッドを持ちます。
setup系メソッドはGlbのstaticメンバーを初期化しますが、
どのメンバーを初期化するかがメソッド毎に異なります。
例えばテストケース用に一部のみ初期化するメソッドがあると便利です。
あるいはGlb依存クラスを他プロジェクトから使用する場合、
他プロジェクトから呼び出しやすいsetupメソッドを用意する必要があります。
その場合設定ファイルの配置等をしたうえでsetupメソッドを呼び出す必要があります。

多くの場合、プロジェクト間でのクラスの共有はあるプロジェクトがデータを作成して他のプロジェクトはただそれを**データとして読み取るだけ**です。
つまりクラスの全機能が使える必要は無く、ゲッター以外要りません。
Glb依存は多くの場合複雑なメソッドで生じ、メンバー変数の初期化やゲッターでは生じないので、そのような条件を満たせばGlb依存していても問題無く利用できます。
Javaの実行において、依存したクラスのロードはそれが必要になるまで行われません。
つまりゲッターを使うだけならGlb関連の依存関係を解決する必要はありません。

実際、その動作をテストしました。
 - クラスA,B,C
 - Aはメソッド部でBに依存、メンバー変数でCに依存
 - Aをシリアライズしてファイルに保存、Bのクラス定義を削除して次のテストでファイルを読み込みデシリアライズ。
結果：デシリアライズしてCにアクセスできるが、Bに依存したメソッドは実行できない。

さらにテストしました。
メンバー変数の初期化に他クラスのstaticメソッド等を使用していて、デシリアライズの段階でそのクラス定義が無かったら、
どの範囲まで動作するか？
結果は、デシリアライズ自体が失敗しました。
デシリアライズは初期化処理を呼ばない事が可能に思えますが、
少なくともKryo5 RC1では初期化処理を呼び出そうとして失敗しました。
デフォルトコンストラクタを呼び出した事でメンバー変数の初期化が行われた結果だと思います。
しかし、初期化処理で間違った値が設定されたとしてもその後デシリアライズ処理の中で正しい値が設定されるので、
初期化処理が動きさえすればそれが無意味な値を設定してもその後に正しい値が設定されます。
これもテストで確認しました。
多くの場合、メンバー変数の初期化処理でGlbに依存するとすれば定数か設定ファイル系なので、
そのようなクラスがnullでも良いから返して動きさえすれば、メンバー変数の初期化でGlbに依存しても多くの場合問題ありません。

Glbに依存したクラスを他プロジェクトから共有する事は留意する事が色々あります。
とはいえ、Glbを使わないコードでも同様の苦労があるはずです。
  
# 最高のプログラミング言語は_考察_案_解釈
このような事をかなり多くの人が思うだろうと思います。
「私の長期的なプログラミングライフに適した最高のプログラミング言語は何ですか？」
あるいは「IT企業としての長期的活動に適した社内標準語とすべき最高のプログラミング言語は何ですか？」

この問題の本質は何か？
- **学習時間を無駄にしたくない**。長期サポートされる開発環境が理想です。言語によってGC等処理系の前提の違い、言語仕様上の概念の違い、周辺のライブラリやフレームワーク等の違いがある。最新の話題をキャッチアップしていく必要もある。だから言語習得は学習コストがかかります。他の言語への乗り換えはそれまでの学習時間を無駄にする可能性があります。**「その都度ぐぐって使うから何も事前に習熟しておく必要が無い」という主張はある程度正しいものの限界があります。運よくいつも全ての必要な情報を検索で見つけられるとか、見つけた情報をすぐに理解して活用できるかという点で楽観し過ぎです**。「その時々の問題を解決できる最も簡単な言語を選ぶ」というスタンスは、長期的に様々な問題を扱っていく場合、毎回異なる言語を選ぶ可能性があり、それなら最初学習コストを払ってでも本格的な言語を覚えて一貫して1つの言語で解決する方が結果的に楽かもしれません。
- **できるだけ可能性が広いスキルセットが欲しい**。その方が何かを作ってみようと思い立つ可能性が高くなります。あるいは、やってみようと思った事を何でもやれるようになります。
- **世界のソフトウェアエコシステム全体で重複したソフトウェアを作らないように**。もし最高のプログラミング言語が明らかになり世界がそれに統一されたら重複したソフトウェアを作る労力を省けます。現状、各言語毎にほとんど同じ内容のライブラリが作られています。
- **コンピューターをプログラミングするという問題に対する解決のフレームワークはどんなものか**。つまりプログラミングとは根本的にどんな問題で、どんな枠組みで解決されるものなのか。例えば[仮想環境言語＋システムプログラミング言語](#仮想環境言語とシステムプログラミング言語)というアイデアはその一種です。つまりその都度自分の状況に応じて適切な言語を考えるのではなく、プログラミングとは何かという事に対して抜本的な解決の枠組みを見出せたなら、ただ1つの最高のプログラミング言語または最高の言語の組み合わせが見つかるはずです。

だから最高のプログラミング言語を考える必要があります。

一般論として、やろうとしている事に応じて選択する事が重要だと言われます。
**ではどんな事にどんな言語が適しているか？そしてその理由は？**

どんな領域があるか？主に使用される言語は？
- OS
C
- デバドラ
C, C++
- 機械語汎用アプリ
C, C++, 科学技術計算ならFotran
- 仮想機械汎用アプリ。バイナリ互換
Java, C#
- スクリプト汎用アプリ。バイナリ互換
Python
- Webフロントエンド
JavaScript, TypeScript
- 組み込み。実質、OSまたはデバドラまたは汎用アプリ。
C, C++, Java

どんな理由でそうなるか？なぜ1言語で全てをやらないか？

**多くの言語でクラス概念が使用されるが、クラス設計が適さない領域がある**。
MMO開発では、ゲームロジックという設計対象自体が常に奇抜な発想を求める不安定なものなので、クラス設計が適しません。**interfaceすら安定しないほどの、まるで予測不可能な概念レベルの変化が生じる対象において、クラス設計は通用しません**。
ちなみに、そこでECSという設計に希望を持つ人も居るようですが、私はECSは悪い設計だと思います。私はその問題について構成ベースの別の設計を思いついたので、近いうちにやってみようと思っています。
さらに、カーネル開発では、抽象的設計の上ではコードがどのようなハードウェアの動作を引き起こすのかイメージしづらく、抽象的設計は必ずしも好まれないようです。主要OSはほとんどCで書かれているようです。Linuxは一度C++に移行しようとしてまたCに戻ったそうです。Cはクラス概念を持っていません。さらにハードウェアの予測不可能な進歩によって抽象的設計はいちいち壊れます。例えばモバイルは消費電力に敏感で、memristorはメモリがプロセッサになります。

クラス設計が適した領域とは？
ほとんどのアプリ。設計を作り込んでいけばやがて安定するだろうと思えるような設計対象。アイデアが変化しにくい対象。ハードウェアの動作を詳細にイメージする必要が無い場合。

少し古い記事ですがRustでOSを作った例について。
http://qwerty2501.hatenablog.com/entry/2017/03/18/224839
あまり良い結果ではなかったようです。C++がOS領域でCに負けている事も含めて、OS領域でCが特に適している事を示唆しています。
一方でC言語はほとんどのアプリ開発に適しません。部分的な関数をCで書くことは多々ありますが、アプリ全体をCで書くことはあまりないと思います。gitはCで書かれていますが恐らくそれはCで大規模プログラムを書くという特殊スキルを伸ばした人が作ったからです。
つまり領域毎に使用言語が異なるという状況は今後も変わりそうにありません。

クラス設計がプログラミングのほとんどの領域で猛威を振るっていますが、それにも関わらず構造体程度の概念しかないCがOSという最重要領域で生き残ります。つまり1言語による完全統一は実現しそうにありません。

**言語によってプログラマーに標準的に期待できる事が違う**。
- フリースタンディングなコードを書くスキルを最も期待できるのはCプログラマーです。
- C++プログラマーは抽象的設計と低水準操作を両方扱います。扱う概念が多岐に渡るので、C++プログラマーは均質性がありません。
- Javaプログラマーはクラス設計に慣れていて、他のパラダイムでコードを書きません。Javaプログラマーは均質です。

**なぜあらゆる言語概念を搭載した言語はダメか？**
あらゆる言語概念を搭載した最強万能言語があったとして、学習コストが高すぎるのでその言語をマスターしている人は限られ部分的にしか使えない人がたくさんいる状況になるし、大勢で1つのコードベースを修正したらソースコードが部分毎に異なるパラダイムで書かれてしまいます。一人で書いたとしても書いていく中で新しい言語概念を覚えたらそこから使いだすわけで、コードに一貫性が無くなります。そのような問題は学習コストだけでなくそもそもどう書くのがベターかという判断の相違によっても引き起こされます。

**問題を多言語連携で解決する**というアイデアもあります。Pythonが機械学習ライブラリをネイティブコードに頼っているように。あるいはJavaがJNIでネイティブコードを利用するように。つまり1つの大きな問題を複数のプロジェクトに分けて、プロジェクト毎に言語を選ぶということです。
多言語連携の長所は、1プロジェクト内では一貫性があるコードが記述される事です。
多言語連携の弱点は言語間連携の部分で新たに留意する事が出てくることです。例えばJNIでは、Java起動オプションでGCを選択できますが、使用しているGCによってJNIの性能がアプリによって致命的なほど変わる場合があるようです。

**性能や大規模開発適性を求めない場合がある**。利用者数や利用頻度が限定的な、業務上必要とされるちょっとしたツールをスクリプト言語で作りたいという需要がある。

このような考えで「なぜ1言語で全てをやらないか？」について私は納得しました。
しかしまだ問題は続きます。最高の1言語を特定できないなら、最高の言語の組み合わせは何か？

- 一般的な評価基準。実績、ライブラリの豊富さ、処理系の性能、解説記事等の豊富さ等。
- 多言語連携前提なので1言語あたりの学習コストが低い事。

それで、私はJava+Cが有力だと思いました。
ところが調査を進めるとC++が恐ろしい可能性を持っている事に気付きました。
私の中で最終的にC++またはJava+Cという候補が残りました。

- C++
    C++は1言語路線の最有力候補。
    学習コストが高い。
    Qtでソースコードレベルのクロスプラットフォームも。
    **1つ恐ろしい可能性がある**。C++はWebAssemblyでWebフロントエンドにも乗り込めるし、WASIプロジェクトの結果次第ではVMすら手に入れてバイナリ互換のクロスプラットフォームすら手に入れる。そこまでいくとJava+Cの対応可能範囲に追いつく。
    今後C++は他の言語に対して本当にその領域でC++を退ける優れた特殊化を持っているかを問います。
    JDKや.NET Coreや主要ブラウザ等はC++で作られている。重要なプログラムほどソースコードが大規模化し性能がシビアに要求されるのでC++で作られる。
- Java+C
    それぞれが単純な言語で大抵の問題を片方で解決できて、ステップアップしやすい事、ソースコードの一貫性を保ちやすい事、そして連携させる事でほぼすべての問題に対応できる事を持ってこれらが最高のプログラミング言語であると考える。相補的。
    いずれも長年最上位のメジャー言語。
    JavaもCも学習コストが低い。両方を学ぶならC++と同じくらいだろうか。
    仮想環境言語+システムプログラミング言語というアイデア。
    他のJVM系言語のソフトウェア資産を利用できる。
    null安全ではないが静的解析ツールで補える。
    ちなみにGWTやteavm等があるもののJSより先にJavaアプレットがあった事を考えると妙な話だなと思います。
    Java+CはWebフロントエンドをどうやるか？実はJavaベースのP2PソフトウェアがWWWを置き換える可能性があります。私は少なくとも技術的にはその方向性が有力と思っています。実際どうなるかは分かりません。しかしもしそうなるとWebフロントエンドという概念自体が無くなります。
    javaバイトコードからLLVM IRへのJITができるとC++とそん色ない性能を出せるだろうと思います。1プロセスで多数のJavaアプリを実行する疑似カーネルという概念が実現されると性能でC++やCを上回る可能性があります。

C++とJava+Cの比較は難しいです。いくつか思ったことを書いておきます。
- JDK自体はjavaで実装できない。一部モジュールはJavaで実装できるが。
- Webブラウザのようなアプレットを扱うホストアプリは別項目に書いたように仮想環境言語で書いた方がアプレットの起動が高速になり総合的に省メモリになります。このようなものでは本来Javaが優れています。
- 戦闘機システム等のラグが許されないソフトウェアではjavaはgcのラグが問題になるかもしれません。それとたぶんJNI連携が多発するので何かソリューションが必要です。

当初私はプログラミング言語の未来についてこう考えていました。
バーチャルプラットフォームなソフトウェアが増える事によってプラットフォームの進歩が激化したり多様化すればC++を含むネイティブコンパイル言語のソフトウェア資産はついてこれないと。
ソースコードレベルではCトランスパイラがあればついていけますが、実行バイナリがバーチャルプラットフォームではないので、再ビルドと再インストールの手間があるから徐々に使われなくなっていきます。
例えばCPU命令セットが急激に多様化した場合、PCを買い替える時アプリを移行できるかということです。アプリがビルドされる時点で存在していなかったCPU命令セットには対応できません。しかしバーチャルプラットフォームソフトウェアはランタイムの更新だけで対応できます。1つ1つのアプリについてリビルドや再インストールが必要なのに対し、ランタイムの更新だけで済むということです。
だから長期的にはバーチャルプラットフォームなソフトウェアが利用者を増やすのだろうと思っていました。
しかしWASIの結果次第でC++アプリもバーチャルプラットフォームになるので、この話は成立しなくなり、最高のプログラミング言語が何であるかという問題は再びはっきりしなくなります。
しかし一言語路線の弱点は、その最有力候補であるC++がOSを記述する言語として採用されていない事です。

ちなみに私はJava+CにさらにTypeScriptを加えようと考えましたが、止めました。Web技術の行方に疑問を持っているからです。JSやTSはwasmによって殺される事は無いと思いますがそもそも[WWWがこける可能性](https://github.com/lifeinwild/tenyu/blob/master/programmingEnvironment.md#Web_%E8%A7%A3%E9%87%88)が気になる。
TypeScriptは主にWeb系で使われ、他の言語よりバグが少ないかもしれません。使用される分野が限定的だからかもしれません。JS周辺のOSSの活発さ(githubから)は圧倒的です。
https://web.cs.ucdavis.edu/~filkov/papers/lang_github.pdf
>TypeScript−0.43 
>TypeScript −1.32 (0.40)∗∗ −2.15 (0.98)∗ −1.34 (0.41)∗∗ −0.34 (0.07)∗∗∗
https://findy-code.io/engineer-lab/github-programming-language-ranking

# LLVM_IRコンパイラの普遍性
従来新しいCPU命令セットが作られたら[とりあえずCコンパイラが作られていた](#C言語の特徴_解釈)と思う。
ところがLLVMが主流になるとLLVM IRからネイティブコードへのコンパイラを作る事が主流になるかもしれない。

# C言語の特徴_解釈
- Cコンパイラの普遍性。最大の特徴。CコンパイラはCPUが存在するほぼすべての環境に存在し、存在しなかったとしても作成するのが最も容易です。https://www.quora.com/What-is-the-most-portable-programming-language >Even if there isn't an existing C compiler targeting a particular hardware platform, it is probably the easiest of all languages to create one. https://www.sigbus.info/compilerbook >コンパイラの制作手法を学ぶために何らかの言語を選ばなければいけないとしたら、Cはさほど多くないリーズナブルな選択肢のうちの一つだと思います。ただし[LLVM_IRコンパイラも普遍性を持ちえます](#LLVM_IRコンパイラの普遍性)
- トランスパイル容易。C言語は機械語と単純に対応づくことからトランスパイルのターゲットにしやすい。
- コンピューターに対する完全な制御性。書いたことしか起きないし、何でもできる。ハードウェアに近い開発で良く使われる。カーネルやデバイスドライバは主にCで作成される。フリースタンディング。
- 高性能。高級言語の中でFortranが最速と言われているが、Cもほぼ同等の性能が出る。
- アプリ開発では他言語から呼び出される関数の実装で使われる事が多い
- 脆弱性が多い。しかし静的解析ツールが解決するはず。https://resources.whitesourcesoftware.com/blog-whitesource/is-one-language-more-secure

# GraalVM_メモ
最強万能ランタイムまたは巨大な泥団子ランタイム。
- lliを内蔵している。LLVM IRは中間コードといってもクロスプラットフォーム性を期待できない。https://www.graalvm.org/docs/reference-manual/languages/llvm/ >Note: LLVM bitcode is platform dependent. The program must be compiled to bitcode for the appropriate platform.
- ネイティブコードの性能が少し落ちるらしい。
 https://hackernoon.com/why-the-java-community-should-embrace-graalvm-abd3ea9121b5?gi=11182f32c16b
 ここのNativeが0.85
- JVMワールドではなくGraalVMワールドになりそう。例えばGraalVMを前提としたbitcodeを含むライブラリが作られる可能性があるが、通常のJVMで実行できないはず。それはもはやJVM系ライブラリではない。
- 2019年5月時点でWindows版が無い。
- Native-Imageでネイティブコードを生成できるらしい。しかし完全対応ではないし、ネイティブ化して配布するならC++とかで作ればいい。
- polyglot
- EEの方が性能が良いらしい

# WebAssembly_HTML5_解釈
本来アセンブリは移植性が低いものだが、クロスプラットフォームが要求されるwebのアセンブリとは何を意味しているか？
WEBブラウザにもともとJS用仮想機械があって、それが中間コードwasmを実行できるようになる。
かつて排除されたJavaアプレットとほとんど同じに思える。

検索するとそれについて述べている記事が見つかった。
https://words.steveklabnik.com/is-webassembly-the-return-of-java-applets-flash
JavaアプレットはHTMLやCSS等Web技術と統合的でなかった、と。でもJavaFXはCSS対応している。
さらにJVMとの違いとしてメモリを手動管理できる。よりシビアな性能のため。でもWebページ上でそんな壮大なゲームや科学技術計算をやるか？GC言語の方が開発効率が良いと言われてるから、GC無しで性能を求めるようなプロジェクトは開発効率を犠牲にしてでも性能を求めてるわけで、あまりWeb上でやるものと思えない。

コア開発者にその質問をぶつけた人が居ました。
https://github.com/WebAssembly/design/issues/960
jvmや.netはセキュリティ上の問題があった、と。
でもそれはエンジニアリングの問題のはずで、結局のところやはりJDKや.NETと被るもので、ただ自分達の方が高品質なエンジニアリングができるという事だろう。

WebAssemblyをブラウザ外で使おうという動きもあるようです。WASI

# Web_解釈
迷走する巨大エコシステム。
JS、HTML5、WebAssembly、しかもWASIでブラウザ外へ。Webで壮大なゲームや科学技術計算、P2Pまでやる。

WebがOpenJDKや.NET Coreを無視してwasmやwasiで独自のランタイムを作った事は世界的利益のためにソフトウェアプロジェクトが連携できない事を示している。それこそが世界のソフトウェアエコシステムの課題なのでは？
要するにソフトウェアエコシステムに世界的な統合性が無い。

主要ブラウザはC++で作られているが、**Javaアプレットの起動はブラウザ自体がJDKベースで作られていたら高速だったろう**。
今Wasmが必要とされている事は、最初からブラウザをJDKベースで作りJavaアプレットの高速起動を実現すべきだった事を意味しているのでは？というのも、以下のシナリオが考えられるからだ。  
**WASIがブラウザ外の仮想機械を作るならブラウザをその仮想機械上で作る事が考えられる**。
そして仮想機械を普及させてブラウザと無関係なアプリも含めて全てのアプリをwasmで作ろうとし始める。
そのため豊富なAPIを備えるようになる。
Webのランタイムとしてセキュアなサンドボックス実行をするという特徴は変更され、何でもできるランタイムとなる。
Webページ用途はオマケとなり、WasmAppletと呼ばれるようになり、権限が制限されて実行される。
GCはほとんどの開発でメリットがある偉大な判断の1つだからそのうち搭載される。
JITも折角中間コードがあるなら搭載される。実行時情報を用いた最適化ができる。
そして需要が高い機能が標準APIとして搭載される。
気付いたらWebページ外での実行が主な用途になる。
WebページはWASI仮想環境が提供する豊富なAPIを利用したwasmアプレットを実行し、ブラウザ自体がWASI仮想環境で動作しているので起動処理が無く高速で省メモリ。
**つまりJDKと同じものになる**。

**ここまで考えると、アプレットのWebページを実現するにはブラウザ自体を仮想環境で作るべきである事が分かります**。ブラウザ全体で省メモリにする、ファイルサイズを抑えるといった事を総合的に考えると、**Webページ上で実行されるアプレットと同じ仮想環境でブラウザを作った方が合理的です**。もしWebブラウザがJavaで作られていたらJavaアプレットは起動が高速で省メモリだった、という事です。
もし本当にWebがそこに到達したら、Javaアプレットを排除した判断は間違いでブラウザがJDKベースで作られるべきだった事を自ら証明します。
そうじゃないというならwasmやWASIのターゲットは何か？どこでこのシナリオから外れる？

最も活発なエコシステムを持つJSからスタートして注目される、Webという最大のエコシステムで採用されて注目される、ブラウザ外へ進出する、GCを持たせずメモリを手動管理する言語をサポートする事で優れたベンチマークが多数発表される、高性能というイメージを持たせる事に成功したらGCオプションを実装する、人々はほとんどのアプリを開発効率を理由にGC言語で書く、成熟してみればJDKや.NET Coreと変わらなかった事に気付くがその頃にはそれらは死んでいる。うまくバズっている面があるのではと思います。

WebAssemblyやWASIは新しい発明や思想がないように見える。最終的にJDKの同等品に行き着くように思う。

# 実行時依存性解決_案
JDKが実装するのが良いだろうと思います。

Googleのような圧倒的なインフラを持っているところが、Maven Centralやjcenterのミラーを世界中の**エンドユーザーに提供**し、**エンドユーザー環境でローカルリポジトリを構築する**。そして**アプリケーションはpom.xml等に依存関係を記述し、pom.xmlをjarに同梱し、実行時にエンドユーザー環境で依存解決する**。なお現状Maven Central等にエンドユーザーがアクセスする事はサーバへの虐待で、実行時依存性解決を実現するには桁違いのインフラが必要です。
エンドユーザー環境でローカルリポジトリが構築されると、他アプリによってDLされたライブラリを再DLしたり同梱する必要がありません。

従来、アプリケーションは他のアプリケーションと同じライブラリを同梱している可能性がありました。しかし実行時依存性解決ではライブラリを重複して配布する事が激減します。ローカルリポジトリは各バージョンのライブラリを持つので正しく依存関係が解決されます。ローカルリポジトリは徐々に肥大化していくので、使っていないライブラリについて定期的に削除する処理が必要です。現時点でmavenはローカルリポジトリに対してそのような処理を行うようになっていません。  
実行時依存性解決ならアプリをいくつインストールしてもライブラリはファイルシステム上で共通です。ライブラリの重複した配布が無くなるので、プログラム全体のファイルサイズは小さくなります。ファイルのキャッシュが効く場面が増えるし、近年ストレージの変化はHDDからSSD、さらにNVMe SSDやoptaneなど、ストレージ容量が小さくなる傾向があります。  
semantic versioningあるいはそれに準じるバージョニングルールが守られれば、脆弱性があっても自動的に依存関係をバージョンアップして解決できます。エコシステムにおけるバージョニングルールの遵守は最大の課題です。  
プログラマーからすればライブラリのマイナーアップデートのためにアプリをアップデートする必要が無くなります。エンドユーザー環境で起動のたびにその時点の最新のライブラリを自動的に使用できるからです。このアイデアは世界で実行されるソフトウェアの品質を飛躍的に高める可能性があります。一方で、主要ライブラリに後方互換性の問題が生じると、多くのアプリが一斉に動作不可能になります。非クリティカルなソフトウェアに向いた仕組みだと言えます。  

このアイデアをライブラリだけでなくJDKやそのモジュールに広げる事も可能そうです。各ライブラリやアプリが依存しているjdkバージョン及びモジュールをpom.xmlのようなもので明示し、実行時依存性解決において自動的に必要なモジュールがインストールされ、それで起動されるというアイデアです。

この構想はOS側JDKを前提としていて、リモートリポジトリにアクセスできる環境でなければ成立しません。
しかしこの構想が成立する場合、Java9+のJigsawを不要になります。

私はこのシステムをTenyutalkというソフトウェアで実装するかもしれません。

# Jigsaw_解釈
自己完結型はJDKのバグを残す可能性が高い。
世界にばらまかれた自己完結型アプリはいずれ更新されなくなり、JDKの良く知られた脆弱性を残したままになる。
非自己完結型なら、OS側JDKを更新するだけで全てのアプリがJDKのバグを修正できます。
自己完結型はアプリのバイナリ互換性を失わせる。バイナリ互換は仮想機械の利点です。
多くの場合、自己完結型を作るならそのプロジェクトはC++を使うべきです。

# 世界的なソースコード検索システム_案
githubやMavenセントラル等ソフトウェアを管理しているところが提供する。
IDEはメソッドの呼び出し元を検索する等できるが、
そのような機能をオンラインで膨大なソフトウェアに跨って提供する。
クラスの世界的な利用状況をモニタリングできる。
世界の状況に対応したエンジニアリング、膨大な実装サンプルの検索。

# 私が空想する少し未来の理想的なプログラミング環境_案
- OS側JDK
- OSコール系APIを強化し[fat java案](#fat_java_案)やJNI用実行時コンパイル案を採用しバーチャルプラットフォームを追求したJDK
- 実行時依存性解決をサポートしてライブラリのためにアプリをアップデートする必要を無くす
- 完全にバーチャルプラットフォームな豊富なライブラリ
- 仮想デスクトップ機能によるreproducible buildsをサポートしたgithub

# Lombokの使用範囲_考察_解釈
EqualsAndHashCodeアノテーションのみ使用する意味がありそうです。**メンバー変数を修正した時にequalsとhashcodeの再作成をし忘れると根深いバグを作るから**です。ボイラープレートの排除が目的ではありません。コンストラクタやアクセサはコンパイルエラーで気付きそうです。  
しかし、Lombokを使用する事自体が問題を起こすかもしれないので、私は結局Lombokの使用に懐疑的です。

# プログラミングの本質的進歩とは_解釈
言語仕様、開発ツール等が以下のように改善すること。
- 最も困難な開発においてプログラマーを助ける。
- 不可解なバグを減らす。
- プログラマーを騙さない。
- 間違いが起きたとして、影響が軽微またはすぐに気付く。

# 汎用プログラミング言語でビルド処理を書く_メモ
普通ビルド処理はant等で書かれます。私は昔からそれが疑問でした。それで私はJavaでビルド処理を書いた事がありますが簡単でした。commons-ioが便利です。
最近Gradleというものもでてきて複雑なビルド処理ができるようです。しかし私はやはりGradleの必要性が分かりません。
ビルド処理を統一的に記述したいから？統一的に記述すると可読性が高まりますが、Gradleの言語を強制されてしまいます。アプリと同じ言語を使えた方が可読性が高いです。

antやgradleの必要性は分かりませんが、mavenのpom.xmlの「プロジェクトのメタデータを宣言的に記述する」というアイデアは優れています。
そのアイデアは1プロジェクトのビルド処理の範疇を超えて、世界的なプロジェクトの整理や連携に影響します。
しかしpom.xmlは依存ライブラリのハッシュ値を記入していないのでリモートリポジトリを全面的に信用している状況にあります。
もしビルド処理でpom.xmlの情報やmavenの機能をプログラムから使用したい場合maven aetherというライブラリがあります。

さらに、プログラミングではテストデータの修正が必要になることがあり、そのためだけの修復コードを書く場合があります。
それもある種のビルド処理に分類されると思いますが、それも汎用プログラミング言語が適しています。

# プログラミング言語によるビルド処理が必要になった場面_経験
ビルド直前にフォルダやファイルのコピーをしたい事は良くあります。
あるプロジェクトでsrcフォルダにシンボリックリンクを使っていましたが、
OracleJDKから他のJDKへの移行でシンボリックリンクの扱いが変わったようでビルドに失敗するようになりました。
試した範囲ではcorrettoとlibericaはsrcフォルダ中のシンボリックリンクに対応していませんでした。
それで結局Javaでビルド処理プログラムを作成して必要時にフォルダごとコピーするような方法で解決しました。

シンボリックリンクが解決してくれるのはフォルダやファイルに関係する問題だけであり、
あらゆる複雑なビルド処理を想定した場合、Javaでビルド処理を書けた方が対応力が高いです。

あとシンボリックリンクは1つ面倒な事がありました。  
a/b/c.txt  
a/b/d/  
a/e/  
フォルダa配下のファイルのうち大部分は別フォルダと同じものを使いたいがc.txtだけ自前のを使いたいとなった場合。
a,bをシンボリックリンクにすることはできません。
d,eフォルダをシンボリックリンクにする事はできます。
もし「c.txtだけ自前のを使いたい」という事情が無ければaをシンボリックリンクにするだけで全て解決します。
つまりただその1ファイルの事情が生じただけで細かくシンボリックリンクを作成する必要が生じます。
そのような細かい管理が生じるので、プログラミング言語でフォルダコピー等のビルド処理を書いた方が楽な方法が見つかります。

# P2P_PKI_メモ
※この項目はTenyuについて考える中で私の中に長い間存在していたいくつかの疑問に対する答えです。たぶん意味不明と思います。

ここでP2P PKIと言っているものはTenyu基盤ソフトウェアです。
- 従来のPKI概念ではなく独自のPKI類似システムを作る理由は何か？
- P2P PKIは外部システムに認証機能を提供すべきか？
- P2P PKIの守備範囲を明確化できるか？それはあらゆる観点から評価して合理的妥結か？

従来のPKIは**どの現実の組織と通信しているかを確認する**という観点に立っていたと思います。
私はP2P PKIについて考えました。それは現実の組織を認証するためではなく、
**ネット上の主体を認証するため**にあり、**P2P PKIにおける信用はネット上の活動を通じて創造され、現実の組織の信用を流用しません**。

**P2P PKIはネットユーザーの信用の数値化や現在のIPアドレスやP2Pネットワークで共有されたファイルやDB等を外部アプリに提供できます**。
P2P PKIはサーバーモードを設定できて、エンドユーザー環境とサーバー環境両方をサポートします。
そしてインターネットを新たな信用を創出する場にする。それはそこに新たな経済を創出しうるという事です。

# OOPとは_説明_解釈
オブジェクト指向という言葉は大まかに分けて3種類の意味があります。

- アランケイのオブジェクト指向。
    https://ubiteku.oinker.me/2016/05/09/what-is-oo-all-about/
    ＞ケイ氏は、オブジェクトを、ネットワークを形成してメッセージを送り合うコンピュータのメタファーとして捉えており、インターネット上のサーバーのように、リクエストをメッセージとして受け取り、そのメッセージをサーバー側で解釈して何らかの処理を行うというモデルを想定していた。

    一見するとこの意味のオブジェクトはカーネルが実現しているプロセスという概念に一致するように思えます。基本的にメッセージングはプロセス間で行われます。しかしオブジェクトレベルのメッセージングも実現されています。RMIがそうです。
    ダイナブックやSmalltalkを見ると、アランケイはユーザー中心のコンピューティングという思想を展開していて、そのイメージはプログラミング言語だけでなくOSか仮想環境を含んだものだったと思います。
    アランケイのオブジェクトはRMI的なフレームワークを標準搭載したプログラミング環境におけるオブジェクトだったろうと思います。
    しかし大抵のオブジェクトは小さいのでメッセージングではなく単にオブジェクトの全情報を通信する事が多いです。

    [Tenyutalk](#Tenyutalk_案_独自ソフト)はユーザー中心コンピューティングのための統一的環境を設計する事を目標にしたソフトウェアです。

- JavaやC++で用いられるオブジェクト指向。
    **実はこの意味のOOPは構造化プログラミングです**。
    **そしてアランケイのOOPはC++等に何ももたらしていません**。
    共同詳細化がinterfaceにまつわる概念で、抽象データがabstract class、抽象化文がそのメソッドです。
    https://ja.wikipedia.org/wiki/%E6%A7%8B%E9%80%A0%E5%8C%96%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0
    ＞抽象データとその上で動作する抽象化文の共同詳細化

    なおこの観点はwikipediaで活動していたMonadaisukiの投稿から影響を受けたものです。

    https://www.cs.utexas.edu/users/EWD/transcriptions/EWD02xx/EWD268.html
    これをJava的に解釈してみる。
    refinementはソフトウェアの洗練、つまりリファクタリング。  

    「抽象クラス等を用いたプログラム(abstract program)の改良において、「連動的リファクタリング」現象を観察した。一部の振る舞いを抜き出した(a given type a certain representation is chosen)1つのinterface型(in terms of new data structures)を実装した複数の抽象クラスにおいて(For abstract data structures of)。その設計判断が少なくとも意味する事は(The immediate consequence of this design decision is)その複数の抽象クラスのメソッド(the abstract statements operating upon the original abstract data structure)は実装するinterfaceを必ず追従して更新されなければならない(have to be redefined in terms of algorithmic refinements operating upon the new data structures in terms of which it was decided to represent the original abstract data structure)。interfaceはソースコード上で独立した単位であるべき(Such a joint refinement of data structure and associated statements should be an isolated unit of the program text:)。そしてinterfaceはその実装クラス群が追従して更新されるという設計判断と(it embodies the immediate consequences of an (independent) design decision and)、プログラムの修正の中で自然に交換可能な単位を記述する(as such the natural unit of interchange for program modification)。これは、私が「真珠」と呼ぶようになったものの一例です(It is an example of what I have grown into calling "a pearl")。」  

    C++にも純粋仮想クラスというinterfaceのような概念があったが、
    isolated unit of the program textという一文はそれを独立した概念として扱うべきことを指摘しており、
    それはJavaのinterfaceのような概念である。
    pearlはカプセル化された振る舞いの単位。そのような単位の実装において他のそのような単位に依存している、つまりあるクラスの定義の中でinterfaceが使用されていて、実行時には何らかのそのinterfaceの実装が選択されているが、その実装の実装でもやはりinterfaceが使用されていて、そのinterface実装interface実装という繰り返しは低水準なところまで続いている、これがneckless。1つpearlの内部に入り込むたびに1つ抽象度が低下し、最後にはマシンレベルに到達する。  

    「interfaceの実装クラス群は何らかの設計上の選択肢を意味するので(As each pearl embodies a specific design decision)、interfaceの実装クラス群はプログラムの修正の中で自然な交換可能単位であり(it is the natural unit of interchange in program modification)、あるいはそれは場合によって要件の変化への適応である。 (or, as the case may be, program adaptation to a change in problem statement)」  

    そしてエドガーダイクストラはpearlのハードウェア実装について語り始める。実際それはJDKというある種の仮想環境でハードウェアではないが実現された。ハードウェア実装は固定長である必要がありPearlが内部に持つデータはたびたび可変長になると思われるので実際のハードウェアによる実装は無理で仮想機械による実装になる。  

    「interface振る舞いを実装したクラスとそれによる実装の選択可能性は(Pearls and necklace)抽象的な部分が残され実装を選択しきっていないプログラムへ実装の選択というある種の設定値を与える作業である(give a clear status to an "incomplete program")、不完全な実装とはそのinterfaceと実装の繰り返しの下部実装を排除した場合の上部実装である。(consisting of the top half of a necklace;)。下部実装はコンピューターで実装可能であり上部実装はそのプログラムとみなせます(it can be regarded as a complete program to be executed by a suitable machine (of which the bottom half of the necklace gives a feasible implementation))このとき上部実装は下部実装に拠らず意味的に確立している(As such, the correctness of the upper half of the necklace can be established regardless of the choice of the bottom half)。」  

    エドガーダイクストラはその上部実装を、下部実装を実装したコンピューターの"マニュアル"と表現した。マニュアルは機械の操作手順のようなニュアンスだろう。マニュアルという表現が与える印象は、その下部実装コンピューターは汎用コンピューターというニュアンスから離れてそれを操作する事がマニュアルと表現されうるような特定目的の汎用性が限定された機械の操作手順ということ。
    そして完全にJavaのinterfaceに相当する概念に言及している。  

    「上部実装と下部実装の間を切断できます(Between two successive pearls we can make a "cut",)。上部実装は下部実装が提供する機械の操作手順です(which is a manual for a machine provided by the part of the necklace below the cut and used by the program represented by the part of the necklace above the cut.)。その操作手順は上部実装と下部実装の間の規格を意味します(This manual serves as an interface between the two parts of the necklace.)。我々はそれを上部と下部の間の規格(data representation as an interface between operations)として捉えるよりも要件の変化に適応するためのプログラムの修正における実装の交換性を確保する(ensuring the combinatorial freedom required for program adaptation)ために役立つと考えます。」  

    data representationはオブジェクトの振る舞いobject behaviorというニュアンスだろう。一時の場面に着目すれば下部実装が上部実装に対して見せるものはオブジェクトの振る舞いだが、より長期的に捉えれば実はそれは下部実装の交換可能性である、と。  
    規格というと機械の連携のためというニュアンスで、それは例えばABIなども含まれ広く連携のための概念だが、要件の変化に耐えるための実装の交換性という捉え方はソフトウェアプロジェクトの一生がイメージされている。  
    エドガーダイクストラは1つのソースコード上で各interfaceの実装クラスを選択した時のその実装クラス群を家族familyと呼んでいるようだ。注意点として家族は同じインターフェースの実装クラス群ではない。1つのソースコード上の全interfaceにおける実装クラスの選択の結果が家族である。つまりDIフレームワークが提供する一括的な実装の選択、その結果がfamily。  

    「interfaceによる実装の交換可能性はプログラムが潜在的に様々なバージョンを実現する唯一の方法です(The combinatorial freedom just mentioned seems to be the only way in which we can make a program as part of a family or "in many (potential) versions" without the labour involved increasing proportional to the number of members of the family)。(The family becomes the set of those selections from a given collection of pearls that can be strung into a fitting necklace.)。」  

    エドガーダイクストラは今日のDIフレームワークのようなinterfaceを作りまくり実装を任意に選択できるプログラミングを構想していた。[Neckless言語](#Neckless言語_解釈_説明)

    Simulaは構造化プログラミングに分類されていますが、既にクラスを扱っていました。
    https://ja.wikipedia.org/wiki/Simula
    ＞クラス（class）の構文と対象（object、オブジェクト）の概念を初めて導入した言語である
    今日のOOPに影響を与えたのはダイクストラの構造化プログラミングです。
    https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0#%E6%AD%B4%E5%8F%B2
    ＞部品化を推進する仕組みが提唱され構造化プログラミング (structured programming) として1967年[要出典]にエドガー・ダイクストラ (Edsger Wybe Dijkstra) らによってまとめあげられた


- プロトタイプベース   
    これは構造化プログラミングともアランケイのOOPとも全く違います。
    https://www.ibm.com/developerworks/jp/web/library/wa-protoop/index.html

ということで、**Java等のOOPをStructured Programmingと言い換えるべき**です。
でもSPと言っても通じないから難しい。
OOPという言葉で指定される意味にはユーザー中心コンピューティング、SP、プロトタイプがあります。

# 継承より構成_比較_考察
構成＝compositionとして使っています。合成と言われる事もあるようです。
私は継承ベースで設計していて、本当に継承で設計していいのか時間をかけて検討しました。
結論から言うと、継承とユーザーコードによる構成はどちらも問題がありました。

構成の問題点
- 構成で継承を代替しようとするとユーザーコードによる相互参照が生じる。
- 継承において仮想メソッドを通じて子クラスが親クラスのメソッドの動作を変更ないし実装する事ができる、言い換えれば親クラスが子クラスに依存したり実装を委譲できるが構成ではそれが出来ないかできたとしてもユーザーコードによるもので煩雑。
- 構成で多態性を実現するにはインターフェースを作成する必要がある。高階層な抽象クラス群を置き換える場合、抽象クラスの組み合わせの数だけインターフェースを作成する必要があるだろう。
- 抽象クラスと異なり通常のクラスと記述上変わらないので委譲メソッドが作成されるような構成を想定して設計されている事が分かりにくい。可読性の問題

継承の問題点
- 概念設計の変化によって継承構造全体が崩れうる。
- 親子クラスの相互依存が必要で、かつ直列的な抽象クラスの列という条件をクリアする概念しかうまく記述できない。抽象クラスを自由に組み合わせる事はできない。

この項目では継承も構成もダメだという事について書きます。
他に[新たな言語仕様](#構成的多重継承_素案)について他の項目に書きました。
さらに[継承も構成も問題があるけど避けられない](#問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説)という事について書きました。

継承への注意喚起が行われた事は正しいと思います。プログラムが保守困難になる原因の一部は継承で、プログラマーは継承を警戒すべきです。

継承は親子クラス間の相互依存を言語仕様でサポートしていて、親クラスから子クラスは仮想メソッドによって抽象化されている。それを構成に置き換えた場合、その相互依存をユーザーコードによって記述する事になる。そして仮想メソッドが無いのでより密結合になる。あるいはinterfaceを大量作成するようなコードになる。

継承を構成で書き換えると相互参照が生じる事について説明します。
なお相互参照は循環参照とも呼ばれアンチパターンの1つです。
https://en.wikipedia.org/wiki/Circular_dependency
https://en.wikipedia.org/wiki/Acyclic_dependencies_principle

こういう3階層の継承があったとします。（実際のプログラムではもっと多階層になり状況はより酷くなります）  
Parent2>Parent1>Child  
abstract class Paren2{}  
abstract class Parent1 extends Parent2{}  
class Child extends Parent1{}  

これを構成で書くとこうなります。  
class Paren2{}  
class Parent1{}  
class Child {  
    private Parent1 p1;  
    private Parent2 p2;  
}  

**継承では子クラスは親クラスに依存できます**。つまりChildやParent1はParent2のpublicまたはprotectedな要素にアクセスできたはずです。
**親クラスは仮想メソッドを通じて子クラスで振る舞いを変更できます**。
**このような継承における上下の依存関係を構成で再現する**にはこうなると思います。
interfaceを乱立させるような別の書き方もありそうですが、interfaceの乱立自体が問題になります。  
interface ChildI    //Childの全インターフェース  
interface Parent1I  //Parent1の全インターフェース  
interface Parent2I  //Parent2の全インターフェース  
interface EverythingHolder extends Child, Parent1I, Parent2I{  
    ChildI getChild();    
    Parent1I getParetn1();  
    Parent2I getParent2();  
}  

それで、p1やp2のメソッドを呼び出すときいちいちthisを与えます。するとp1やp2はthisを通じて全オブジェクトにアクセスできるので、継承にあった親子クラスの相互依存を再現できます。  
class Child implements EverythingHolder{  
    private Parent1 p1;  
    public void do(){  
        p1.method1(this);  
    }  
}  
class Parent1{  
    public void method1(EverythingHolder host){}  
}  

メソッドでthisをいちいち与えるのが面倒だからとParent1やParent2のメンバー変数にChildを持たせるかもしれません。
それは継承よりも強い相互依存です。

ここまでの苦労を払って、構成は何をもたらすか？
- p1, p2の動的変更
- 抽象クラスの直列を意識しなくてよくなる。

継承の長所について。
**継承は意味を記述できている**。一般にクラスは様々なメンバー変数を持ちますが、**親クラスを継承する記述は他のメンバー変数のクラスとの意味的な違いを記述します**。
class A extends B{  
    private C c;  
}  
AのオブジェクトはB由来の状態とcを持ちますが、B由来の状態とcではAとの関係性が違います。  
ところが構成ベースで作った場合、親クラスだったものがメンバー変数になります。その意味的な違いの記述を失っていて可読性の低下です。

既に書いた通り、構成で継承を代替すると循環参照が生じます。ホストオブジェクトや多数の委譲先オブジェクトが相互依存できるよう記述する必要があるからです。しかもそれがユーザーコードで生じます。
私は、継承が問題を起こしやすい事を理解できますが、構成が解決策だと思えません。

もし**全子孫クラスが絶対に持つべき状態**があるならそれは継承で与えるべきです。
例えば、継承なら抽象クラスにidフィールドを置いて全子孫クラスに継承させれますが、
interfaceでgetId()があるというだけの制約だとその実装はもしかしたらオンラインアクセスしてどこかから状態を持ってくるかもしれないし、動作の実態に確信を持てなくなります。プログラムではたびたび通信が発生するか、ストレージアクセスが発生するかといった性質が問題になります。あるいは内部のidフィールドから返すにしてもtransientになっているかもしれません。そうするとシリアライズした後デシリアライズした時にidの状態が無くなります。抽象クラスはそのような問題を排除できます。  
とはいえ私は常に構成を使うべきだという人達の意見も分かります。しかし相互参照の記述が嫌です。**継承を一般的に構成に置き換えようとすると子クラスによる仮想メソッドの実装及びそれによる親クラスの動作変更をどう実現するか？が問題になります。**
継承は密接な相互依存関係をユーザーコードではなく言語仕様の上で扱えるという点で優れていると思います。
他にも継承は本番用クラスを継承してテストクラスを作るとか、非常に便利な場合があります。

**特に問題になるのはモデル設計における継承です**。

関連項目
- [問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説](#問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説)
- [構成的多重継承_素案](#構成的多重継承_素案)
- [構成を言語仕様でサポートする_parent_素案](#構成を言語仕様でサポートする_parent_素案)

# 問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説
もし「論理的思考が嫌だ」とか「メソッドやクラスがたくさんあって管理するのが嫌だ」と言っている人が居たら、その人にはプログラミングを諦めてもらうしか無いのではないか？存在するしかない本質的難しさを拒否するなら。私が「本質的難しさ」と言っているのはそのような**拒否できない難しさ**です。
そして継承の問題等抽象的設計の困難を指摘する立場はそのようなものではないか？ということです。

**継承はその多態性による利便性の分だけ設計が難しい**。再利用は良いものだと言われますが、再利用されるほど設計は熟慮が必要になり、設計の更新は難しくなります。プログラミング言語はあらゆる問題を想定する必要がありますが、そのような場合フリーランチは存在せず何かトレードオフがあるはずです。

抽象的設計は様々なプログラムに流用できるはずです。**本当の問題は世界的に抽象的設計を議論したり成果を共有する事ができていない事にあるのではないか？**と思います。

# 構成的多重継承_素案
※結局、ほとんどの場合で[従来の継承で問題無い](#問題は継承ではなく抽象的設計そのもので、しかもそれは本質的難しさではないか？_仮説)と思うようになった。例外はゲーム関係の奇抜なシステムくらいか。

[継承より構成_比較_考察](#継承より構成_比較_考察)の解決策。

多重継承される事が可能なcompositionalクラスという言語仕様を作る。
構成的多重継承はcompositionalクラスを多重継承する。  
ClassA extends CompositionalClass1, CompositionalClass2  
compositionalクラスのメソッドは再帰的に呼び出される。  
ClassA#equalsが呼び出されたら  
CompositionalClass1#equals  
CompositionalClass2#equals  
も呼び出される。  
多重継承の典型的問題としてひし形継承の問題が良く言われるが、この再帰的呼び出しによって解決される。
compositionalクラスは直接newされず、子クラスを通してnewされる。

メソッドの引数の型に複数のcompositionalクラスを指定できたほうがいいだろう。
func(CompositionalClass1 & CompositionalClass2 arg1);

構成的多重継承で横の関係にある抽象クラスが相互依存するにはどうすればいいか？
相互依存させてしまうようではこんなことをやる意味がないが、どうしても必要な場合。

class NormalClassA extends CompositionalClass1, CompositionalClass2  
普通にはここでCompositionalClass1とCompositionalClass2は互いに依存できない。
そこで、仮想メソッドで横の関係にあるクラスの情報を取得できるようにする。  
//CompositionalClass1#  
abstract CompositionalClass2 getCompositionalClass2();  
このメソッドをNormalClassAに実装させる。NormalClassAはCompositionalClass2を継承しているのでthisを返すだけ。  
//NormalClassA#  
CompositionalClass2 getCompositionalClass2(){
    return this;
}
するとCompositionalClass1からCompositionalClass2を参照できる。  

とはいえ結局相互依存しているなら従来の継承と変わらない。
むしろ抽象メソッドへの依存だけでなく直接CompositionalClass1においてCompositionalClass2のimportが生じるから悪化しているか。
結局、継承とは一列のクラス関係における相互依存であり、相互依存せずに済む方法でそれを完全に代替することはできない。

# 構成を言語仕様でサポートする_parent_素案
この案は[構成的多重継承_素案](#構成的多重継承_素案)とかなり類似している。

compositionalクラスという概念を作り、そのインスタンスは
「メンバー変数としての参照が1か所からに限定され、常にいずれかのオブジェクトのメンバー変数として参照されていて、その制約によって常にただ一つの親オブジェクトが存在する事が保証される」というアイデアで、構成の要素側（compositionalクラスのインスタンス）からホスト側（親オブジェクト）へのアクセスを可能にする。

発想の経緯
- [構成の記述では相互参照をユーザーコードで作成する事になる。](#継承より構成_比較_考察)
- [Glbは各モジュールの相互参照をうまく扱えている。Glbは構成的。](#Glb)じゃあもっと粒度の小さいGlbみたいなものを扱おう。

compositionalクラスのメソッドから親オブジェクトを参照できる。  
public compositional class Member<T extends Holder>{  
    public void func(){  
        parent.someMethod();//thisみたいな感じでparentが使える。  
    }  
}  
public class HolderImpl implements Holder{  
    private Member<HolderImpl> m1 = new Member<>();//m1と同じインスタンスへの参照はここにしかない。  
}  
Holderインターフェースはその構成内で相互参照を実現するための、その構成内の標準知識のようなもので、そこに各メンバーへのゲッターを備えれば構成内で相互参照ができます。

さらにcompositionalクラスのインスタンスをメンバーに持つ場合、継承と同様に自動的にそのインターフェースを持つとしても良いと思います。つまりHolderImpl#func()が自動的に存在するという事です。HolderImplがMember m1を持つからm1のメソッドが透過的に見えるという事です。
このルールによって多態性が実現されます。
Memberを期待するメソッドにHolderImplオブジェクトを渡せます。

さらに、あるクラスの全てのcompositionalクラスに特定のインターフェースの実装を強制できるといいかと思った。
例えばHolderImplがそのメンバー変数のうちcompositionalクラスであるものについてvalidate()インターフェースの実装を要求する。
そしてcompositionsというキーワードをthisやparentのように使えて、そのクラス内のcompositionalクラスである全メンバー変数を参照できる。  
//in HolderImpl  
for(CompositionalMember<HolderImpl> e : compositions)  
    e.validate();  
このようなコードが可能になるように。

このアイデアは[構成的多重継承_素案](#構成的多重継承_素案)と類似した事を言っているだけですが、**多態性と横の関係（多重継承やメンバー変数）を維持しつつ相互依存(親オブジェクトparentやcompositionsや子クラス制約等)をサポートするというのが根本的アイデア**です。それをうまく達成できれば何でもいい。

この案はクラスのバージョンアップに強い。
シリアライズされたオブジェクトのクラスのメンバー変数の定義が変わるとデシリアライズできなくなるが、
古いクラス定義を残しつつ新しいクラス定義を用意してDBからの読み取り箇所でオブジェクトをバージョンアップする事が考えられる。
その時抽象クラスの変更は全子孫クラスに影響する（内容が同じ新たなクラス定義を用意する必要がある）が、
メンバー変数の変更なら末端の子クラス1つだけ新しいクラス定義を用意すればいい。
その点でこちらの方が本筋かもしれない。

# Neckless言語_解釈_説明
エドガーダイクストラが言及していたNeckless概念が大体わかった。
JavaのDIフレームワークを用いたプログラミングがかなり近い。
- クラスはクラスに依存してはならない。
- クラスはinterfaceに依存する。
- interfaceは多数の実装クラスを持ちうる。
- 一括でシステム全体の実装クラスを選択するような方法を作る。ダイクストラ的familyを作る方法。

このような原則を徹底する事で実装クラスの交換によるソースコードの状況適応力を最大化する。

しかし私はGlbやcompositionのような方向性が有望だと思う。

私の中でinterfaceとは何か。
約束または規格であり、変更困難な、将来に渡って保証されるシステム上の前提の一種である。そのような概念を見出す事も変更する事も非常に重い。
例えば抽象的な確固たる概念を述べるinterfaceがある。JavaにList,Map,Set,Collection,Iterable等のinterfaceが定義されている。これらが変更されたらほとんどのJavaプログラムは動作しなくなる。
あるいはプラグイン機構を実現するための外部インターフェースがある。もしそれが変更されたら全プラグインを修正する必要がある。
ライブラリが他プロジェクトに公開する振る舞いもしばしばinterfaceとして定義されるが、もし変更されたらそのライブラリを使用している多数のプロジェクトに影響する。

# リリース番号_案
tenyuで用いているリリース番号という概念は、
リリースのたびにそれに依存したデータやソフトウェアが世界のどこかで作られていく、というイメージに基づいている。
公開しない限りどれほど大幅な変更が行われても問題にならない。
”リリース”が意識すべき区切りとなり、ソフトウェアエコシステムに配慮すべき単位を作る。

# ソースコード公開確認API_案
githubやbitbucketは登録されたプログラムの全リリースバイナリについてそのハッシュ値を記録する。
そして入力されたハッシュ値が登録済みか、つまりソースコードが公開されているかを判定できるようなapiを提供する。

# セーフランチャー_案
ソースコード公開確認や作者信用数値を確認するランチャー。
ランチャーソフトウェアで起動直前にソースコードが公開されているかチェックする。
ソフトウェアのセキュリティに寄与する可能性がある。

# 3Dゲームにおける演出用サブ物理空間_案
髪の毛やスカートなどひらひらしたものは物理演算した方が開発効率や見栄えにおいて優位性がある。
しかし主にボーンアニメーションで行われているようだ。
物理演算は重いので慎重に使わないとゲームに適さないが、髪の毛やスカートに限定するなら広範囲の相互作用を無視してもいいので、うまく並列処理できるはず。髪の毛やスカートのひらひらは純粋に演出的でありゲームロジックや対戦における有利不利に影響しないので、1キャラクター内での純粋に演出的な物理演算という事で処理できる。
現在CPUはRyzenによってコア数が急増しつつあるので状況に適している。
技術的イメージは**演出用サブ物理空間を作り1キャラクター限定で演算し、全オブジェクトの相互作用を扱うゲームロジック用のベース物理空間と分ける**。
演出用サブ物理空間はキャラクター毎の空間で、その中で髪の毛やスカート等のひらひらを物理演算する。キャラクターの体の動きや装備品の動き等の影響は受けるが、他のキャラクターの影響は受けない。
つまり髪の毛やスカートは他のキャラクター等と衝突しない。自キャラ内での衝突や速度による変化等が影響する。
一方で、ゲームロジック用のベース物理空間では、キャラクターは1個の球体など単純な図形として扱われ、他のキャラクターや物体等との広範囲の衝突判定が行われる。

jme3のDynamicAnimControlのRagDollサンプルコードは各ボーンに物理オブジェクトを設定したりリンクを設定して運動学的モーションを実現している。その動作はかなり面白いが、モデルの形状によってゲーム上の有利不利が生じるので対戦ゲームでは問題がある。特に使用するアバターを自由化しようとするなら対戦ゲームにおいて当たり判定は全キャラクター共通の単純な形状であることが望ましい。

とはいえ衝突部位に応じて変化する運動学的モーションは演出上魅力的なので、対戦上の有利不利のためにあくまでキャラクターはベース物理空間上で単純な球体の衝突範囲を持つべきだが、その球体の衝突箇所がそのキャラクターのサブ物理空間に通知されて演出だけ運動学的になる、キャラクターの速度はベース物理空間で決まる、というのはよさそうだ。このアイデアは性能と演出のバランスが取れている。

# オンラインゲームの物理演算_案
このようなアイデアは実証しなければあまり意味が無いが、実証できていない。たぶんそのうちやる。
これはゲームロジック用のベース物理空間の話。
一般にオンラインゲームで物理演算は難しいと言われている。
問題
   - キャラクターが位置補正を受けてワープするのがプレイヤーにとってストレス
   - 僅かな位置の違いで当たったか外れたかが変わり、当たった場合吹っ飛ばされるが吹っ飛ばされる角度も僅かな位置の違いで変わるので、物理演算によって僅かな違いが大きな違いに繋がる。
解決策
   - 各プレイヤーキャラクターは自分の位置と速度を**主張**し、他のプレイヤーキャラクターが主張する位置と速度を受け入れる。つまり自キャラがワープする事は無い。他キャラ、他オブジェクトはワープする。
   - HPなどは、ノードに序列をつけて上の序列からのメッセージを採用する。ホスト概念がある場合、ホストノードは最上位。
   - 自キャラの位置と速度について他プレイヤーに定期的に送信して同期する。
      - 自キャラの近くにいるプレイヤーには高頻度で同期する。遠くにいるプレイヤーには頻度を低下させる。
      - 定期的な同期の他にイベントベースの同期を併用する。例えば位置や速度の急変があったら全プレイヤーに送信する。
      - 自キャラ及びペット及び自分の投射物の数はせいぜい5程度と思われる。
      - 位置と速度は1オブジェクトにつき40バイト程度で送信できると思われる。
      - 10人対戦を想定し、他のプレイヤーの人数は9人を想定。
      - 1秒あたり60回同期できればラグを感じないと予想。
      - 送信量 5 * 40 * 9 * 60 = 108KB/s 受信量はその9倍で972KB/s ただしこれは多めの見積もりで、実際自オブジェクト数は2以下と思われるのでこの半分以下で済むだろう。受信量で8Mbpsが最も厳しい性能要件になるものの、最近の回線なら問題ないはず。
      - 同期メッセージは連番のIDを持つ。受信側は最後のIDを持ち、それより新しいメッセージのみ反映し、最後のIDを更新する。
      - 同期頻度が高すぎて回線負荷が高まり、せいぜい数十人程度の同時プレイしかできない。しかしインスタンス空間で限られた人数で開催されるゲームなら可能。

このアイデアはクライアント優先の場合があるのでチートが容易になっているが、Tenyuの場合リプレイファイルや紹介制ユーザー登録などがチート対策になるので問題無い。

# ソフトウェアプロジェクトの死_問題
人気言語ではライブラリが豊富にあるとよく言われます。
しかし大事な事は生きたプロジェクトがどれだけあるかです。
死んだプロジェクトは検索を妨害するし、プロジェクトの死亡率が高いとライブラリ選定における比較検討を難しくします。

# ネットにアクセスするコンピューターの水準を底上げする_問題_解釈
日本のスマホは回線代に端末代が含められている。
そしてユーザーは定期的に端末を無料で最新のものへ交換する。
そのモデルは端末の水準を保つために優れています。

コンピューターはたびたびハードウェアレベルの脆弱性が発見されますが、リコールされません。
コンピューターは性能向上が著しく、数年で買い替える人が多いし、リコールは合理的でない。
定期的に新しいコンピューターに買い替えさせるのが正しい。
それを強制できるビジネスモデルはコンピューターセキュリティにとって有益です。

セキュリティだけでなく、極端に古く低スペックなコンピューターをソフトウェア開発者が想定しなくてよくなる。

PCにおいても水準を保つ工夫が必要です。

# 創発的なソフトウェア_解釈_案_思想
オープンソースや自由ソフトウェア等[FOSS](http://e-words.jp/w/FOSS.html#targetText=FOSS%E3%81%A8%E3%81%AF%E3%80%81%E3%83%95%E3%83%AA%E3%83%BC%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2,%E3%81%A6%E3%81%84%E3%82%8B%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2%E3%81%AE%E7%B7%8F%E7%A7%B0%E3%80%82)が注目される本質的理由はそれら概念が**ソフトウェアを世界の共用資産にする事**になり、ソフトウェアエコシステムにおいて世界的な創発的現象に繋がるからです。
私はソフトウェアのための世界で1つの共同資本という言葉を使う場合がありますが、FOSSの充実は共同資本の成長の1つです。
FOSSの価値観はソフトウェアの生産性にとって最も理想的です。

オープンソースや自由ソフトウェアは世界の共用資産を目指す性格のソフトウェアです。
[TenyuLicenseのソフトウェアもFOSSです](https://github.com/lifeinwild/tenyu#TenyuLicense%E3%81%AE%E6%A6%82%E8%A6%81)。

私はソフトウェアやオンラインサービスについて**創発的**と言う場合があります。
ソフトウェアが創発的であるかは、世界の共用資産である事を目指す性格があるか、ソフトウェアの最大の生産性を目指す性格があるか、創発的現象に寄与するか等が基準になります。
ソースコードが非公開のオンラインサービスでも創発的とみなせる場合があるかもしれません。
つまり、ソースコードを公開したり自由なライセンスにする事は創発的であろうとする一手段に過ぎず、必須の条件ではないという事です。

# 自由ソフトウェア_コピーレフト_オープンソース_TenyuLicense_比較
オープンソースと自由ソフトウェアは作者の経済的利益の達成方法について十分に説明していない。
Tenyuの構想では、ソフトウェアの自由な相互利用と作者の経済的利益を両立できる。
さらに、誰がどの程度貢献しているかデジタルに記述され、その情報が公開される。

# GNUとLinuxとUnix_解釈
GNUはUnixを模倣するために始まりました。
LinuxはMinixを参考にして作られました。
MinixはUnix系OSです。
そのような事実に対して、GNUやLinuxはパクリであると批判する意見を僅かに見た事があります。

Tenyuの構想である作者権やTenyuLicenseは私の創作に対する思想を示したものですが、その観点からすると、僅かでも真似をしたらダメというわけではなく、独自の創作性が十分に入っていて、かつ参考にした他の創作物を明示していればほとんどの場合問題ありません。

GNU,Linux
 - 成果物が無料で公開され世界的な創発的現象を引き起こしました。
 - 社会を騙そうとしていません。何を参考にしたか明示しました。
 - 独創的な創作活動です。

そのようなプロジェクトを否定した場合、100％独自の創作物のみが肯定される事になり、非現実的です。

# リベラル_思想
リベラルの本質は**世界をより創発的にする事**です。
良く寛容さと訳されますが、寛容さは場合によって世界をより創発的にすると思いますが、リベラルとされる行動全般を説明しません。
OSS、途上国の成長を助ける事、子どもの貧困を解決する事、ネットで様々な学習情報が提供されている事などは世界をより創発的にします。
何が世界をより創発的にするかは明白に判断できる場合もありますが、難しい場合もあります。

# staticを使うべき場面_経験
私が遭遇したstaticを使うべき場面について。
- Glbのメンバー変数及びアクセサ
- interfaceに付随した定数。
    interfaceは「仕様を記述している」という意識が強いが、例えば連番のIDで最初のIDが何番か(通例0か1）、特殊な意味を持つIDが何か、-1,-2,-3等が特殊なオブジェクトに設定される場合など、と言った仕様についてinterfaceにstaticに定義している。
- オブジェクトをDBに登録するための一連のDB操作シーケンス。
    複数のストアに一連の操作をするコードはどこに書くか？私の場合、そのような一連の操作の必要性はモデルによって生じていたので、モデルクラスにstaticメソッドとして定義した。DBがグローバル状態の一種であるからこの設計が妥当だと思った。
- 複数コンストラクタ。
    Tenyu基盤ソフトウェアに含められているIDListクラスは膨大な数値配列または数値リストを受け取って、それを圧縮した1オブジェクトにする。
    この圧縮アルゴリズムは優秀でデータにもよるが10～20分の1まで圧縮できる。
    しかしintの範囲に限られていてlongに対応していないので、
    long範囲を扱う工夫としてstaticメソッドとしてList<IDList>を返すメソッドを定義した。
    「そのクラスのオブジェクトを多数コンストラクトするメソッド」はコンストラクタにできないし、
    staticメソッドにしておくのが一番まとまりが良い。

# NVMe_SSD_予想
NVMeを使ってもゲームのロードが高速化しないという話がありますが、恐らくCPUのコア数が不足しているか、ゲームがアセットを並列にロードしていません。
アセットは大抵の場合圧縮されていたり、ゲームエンジンにとってネイティブではない形式で保存されているので、変換処理が必要になり、アセットを読み込む時にCPU負荷が生じます。
今後CPUのコア数が増えると思うのでNVMeはゲームでも有力なはずです。

# デシリアライズ用コンストラクタ_案
Kryoなどシリアライザはコンストラクタを呼び出さないとフィールドを初期化できない。
そのせいで、初期化処理が走った後に再度メンバー変数に値が設定されていて二度手間になっている面がある。
デシリアライズ用のコンストラクタを暗黙的に備えて、一部の初期化処理をシリアライザに委譲すれば解決するはず。

# OSがLLVM標準搭載_案
OSがLLVMを標準搭載するとLLVM IRを実行できるので、プログラムをLLVM IRで配布する事を標準化できる。
IRは特定の命令セットに依存している場合があるが、依存していない場合もある。
OSがIRプログラム起動時にIRから機械語へのコンパイルをLLVMによって行い、それを実行する。コンパイル結果をキャッシュする。
こうするとLLVMが新しいCPUに対応すれば既存のプログラムが同時に対応完了する。
ただし特定の命令セットに依存しているIRはそうではない。

# CPU命令セットの爆発的多様化によるセキュリティの改善_予想
任意の機械語を実行可能な脆弱性がどこかで発生し、攻撃者が任意の機械語ウイルスを実行させるとして、もしCPU命令セットが多様化していると正しい命令セットを特定できずに失敗する。
あり得る全ての命令セットについて網羅的に実行していったら？無意味な機械語ウイルスを実行した結果としてプロセスが終了する。
実行中のプログラムに、その脆弱性を突いて任意のコードを実行させる場合、基本的には何らかの機械語を流し込む事になる。システムによってはSQLや中間コードを流し込む場合もありうるが。
だからCPU命令セットの多様化は潜在的にセキュリティを改善する。

# OSは多様化するか_予想
OSはデバドラの移植が難しい事によって守られているので無理だろう。
しかしLinuxディストリの多様化や既存OS間での移行、マルチブート環境が広がる事はありうる。
Fuchsia等新しいOSも開発されているが、今のところ流行る気配はない。
新しいOSが使用されるとしたら周辺機器を決め打ちできるスマホ等で、多様な周辺機器を扱うデスクトップPC用途では難しいだろう。

# LLVMとJDK_考察_案_メモ
AzulのfalconやRoboVMが既にこのアイデアを実現し良い結果を得たらしい。

他にSharkというプロジェクトがLLVMによるJITを実現したようだ。
しかしZeroというマイナー環境向けにOpenJDKを作りやすくするためのプロジェクトにおいて使用するマイナーなものという位置づけでしか捉えられて無さそう。
https://icedtea.classpath.org/wiki/ZeroSharkFaq

理想的にはOSがLLVMを標準搭載すべきだろう。
LLVM（というよりJIT系のアイデア）とOSを統合的に考えると最適化された実行バイナリをキャッシュする仕組みが考えられる。

LLVMに最適化を任せる事でJDKの開発者はCPUアーキテクチャ固有の最適化等について悩む必要が無くなる。

# プログラムの統一_プログラマーの均質化_案
プログラムは統一的に記述されたほうが可読性が高まり良いだろうというアイデア。
性能やセキュリティの違いがあってやっているなら良いが、無駄な不均質化の場合もある。
システムの設計パターンも統一した方が良い。Glbを使うかDIフレームワークを使うか等。
ライブラリも統一された方が良い。

# Moduleとアドイン
moduleがアドインに対するセキュリティを実現するか？について考えていました。
自分の結論は、moduleは**セキュリティのためではなく**主にJDKのモジュールやライブラリやアドインを活用するホストプログラムの**保守性のため**に生じたものであり、「それに依存したプログラムを作らないで欲しい」という目的を叶えるものです。一方でセキュリティ目的であれば読み取り系インターフェースへのアクセスは許可したいが書き込み系インターフェースは禁止というような、インターフェース単位での細かな設定か、各情報への読み書き権限を管理するような事が必要になります。保守性とセキュリティには本質的な齟齬があり、それはmoduleのパッケージ単位での公開設定という粗い設定に表れています。**要するにmoduleはセキュリティのためではなく保守性のために使用するのが正しい**。  

一方でOracleの文書にこのように書いてあるからセキュリティ目的も期待していいのかと思ってしまう。
https://www.oracle.com/webfolder/technetwork/jp/javamagazine/Java-SO17-Modules.pdf  
>攻撃者がアクセスできるクラスが少なくなるため、プラットフォームのセキュリティが向上します   

ここでいうセキュリティの向上とはほとんど宣伝文句であり、まともなセキュリティソリューションであればインターフェース単位での細かな制御や各データへの読み書き権限管理が必要なところ、moduleはパッケージ単位でのアクセス制御を記述します。その仕様は保守性のためにのみ適切に機能します。アクセスできるクラスが減る事は実際にはほとんどセキュリティを向上させません。ほとんどのアプリまたはアドインがファイルシステムAPIやDBや通信APIに依存している以上、攻撃者はそれらのAPIを使用してほとんどすべての攻撃が可能です。  
>コンパイル時と実行時の両方で依存性を認識できます。   

これもセキュリティソリューションであることを期待してしまう仕様です。しかしこれは恐らく保守性のためにリフレクションなどで実行時にカプセル化されたクラスにアクセスすることを防ぐためにあり、やはりセキュリティソリューションではないのだろうと思います。  

moduleは保守性のために使うものだと考えれば使い方がとても分かりやすいです。セキュリティのために使うものではない。

moduleに対して自分の中にあった疑問を整理します。
- 依存性解決。moduleはこれを解決しない
- 実行時依存制御。moduleはこれを提供するが、あくまで保守性のため。
- アドインに対するセキュリティ。moduleはこの目的のために役立たない。
- 完全なカプセル化。moduleはこれを提供する。しかし--add-opensや--add-exportsによってカプセル化されているパッケージにアクセスできるようだ。どの程度意味があるのか？
- 自己完結型。非常にメモリが限られたコンピュータでは利点だろうが、同時に[Moduleに疑問を感じる最大の理由](#自己完結型の否定_批判)でもある。そのような限定的用途のためになぜエコシステム全体がJPMSのための作業を強いられるのか？

moduleはjar hellを解決すると紹介されていることがあったが、依存性の記述においてバージョンを指定しないのでjar hellを解決できる可能性は無い。
例えばこの記事がそれについて言及している。  
https://blog.codefx.org/java/dev/will-there-be-module-hell/  
Moduleは依存性解決を対象としていない。  
https://softwareengineering.stackexchange.com/questions/358396/how-does-java-9-manage-module-versions  
http://openjdk.java.net/projects/jigsaw/goals-reqs/03#versioning  

jar hellを解決するなら[mavenとjdkを統合する](#実行時依存性解決_案)必要があるだろう。
なおmavenとjdkを統合するアイデアを考えると、その時pom.xmlとmodule-info.javaが競合する気がします。

SecurityManagerでアドインに対するセキュリティを実現できる。セキュリティ目的であればこれを利用すべき。
カスタムパーミッションで自分のクラスへのアクセスに自作のパーミッションを必要とするよう設定できる。  
https://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=88487519  
インターフェースまたはクラス単位でどのスレッドグループにアクセスを許可するかをアノテーションで指定できると良さそうだがそういう方法は無さそうだ。

**保守性のための依存性制御とセキュリティのための依存性制御があり、前者はパッケージ単位での指定で機能するが後者はもっと難しい問題になる**。

# １プロセスで多数のJavaアプリを動かす_案
**1プロセス上で多数のJavaアプリを同時実行すると起動時間を極小化できて省メモリになりJITも効率が良い**。JDKがそのようなオプションを持ったらどうなるか、疑似カーネルのようなものが必要だろうとたまに考えている。
しかし各アプリは独自のOSレベルのプロセスを持てないので互換性がないものが出るかもしれない。
この方がクラウドにおいてもネイティブ化より性能が良いのではないか。

# Javaの複雑化_愚痴
言語は単純であるべきだが、複雑化する一方だ。
Javaはエコシステムが巨大で歴史が長いせいもあるだろうがどの領域にも複数の選択肢がある。

- JavaエコシステムのGUIフレームワークは主なものに限定してもAWT, Swing, SWT, JavaFXと4種類あり、公式かつ最新のJavaFXがランタイムから分離されていて、古いSwingが同梱されている。
- サードパーティライブラリも乱立している。しかも1つの領域に利用者数が多いライブラリが複数ある。
- 継承か構成か？構成が推奨されるが相互参照が生じ、ユーザーコードによる構成にも問題を感じる。

このような状況はJavaソースコードを不均質化させていく。
世界的なJavaソースコードの統一的記述が達成された方が可読性やプログラマーの均質性が高まる。

Javaエコシステムの複雑さのせいで、私はTenyuプロジェクトのソフトウェア構成の判断において色々な比較検討をさせられた。
実際の使用経験無く評判や概要に基づいて判断した。いちいち詳細に調べていられない。

Netty vs Grizzly
私はNettyを選んだ。Nettyはベンチマーク結果が良かったり実績が豊富だった。

libgdx vs jmonkeyengine vs JavaFX
私はjmonkeyを選んだ。3Dを主眼にしているようだったから。
JavaFXは3Dも出来るがゲーム用途では実績が無さすぎる。
なおここに挙げた以外でもマイナーなものがたくさんある。

2Dの簡単なゲームにJavaFXを使うというアイデアはよさそうに思う。2Dゲームを作るにしてもlibgdxかjavafxかという事になる。
http://almasb.github.io/FXGL/

JavaFXを使うにしてもFXMLかコードかで分かれる。JavaFXのscene builderを少し使っていたが、直接コードで書いた方が良いと判断した。

何にせよ**選択肢が多い上に簡単に優劣をつけられないからJavaソースコードの不均質化及びJavaプログラマーの不均質化の原因になる**。せっかくの巨大エコシステムが無駄になっているというか、むしろ不均質化を招いているという点で問題を作っているように感じる。

# JavaFX
まず、JavaFXに関して様々な問題を認識したにも関わらず、なぜか私はJavaFXが好きです。
- SceneBuilderを使っているとできないことがたくさんある。FXMLも不要。利用を試みて時間を無駄にした。
- 直接Javaコードを書くのが最も楽で適切な設計に到達できる。
- プロパティバインドしようとするとモデル側にjavafx.beans系のクラスが出てきてモデルとビューの分離に問題が生じる。利用を試みて時間を無駄にした。
- プロパティバインドを使ってもDBからモデルデータを読み出すシステムの場合ほとんど役に立たない。値の更新はDB上で行われそれを再読出ししなければならない。永続化されずリアルタイムに変更されるモデルデータでのみバインドは有効。DBまで一貫した仕組みを提供しなければコーディング量を減らせない。
- Swingに対して特に利点がない。強いて言えばラムダ前提で設計されているのは利点か。
- アプリのGUIをキーボードショートカットのみで操作できるようにしようとしたらずいぶん苦労した。
- JavaFXが牽引力を持っていないという記事。https://www.codenameone.com/blog/should-oracle-spring-clean-javafx.html
- その記事のコメントにおいてJavaFXで問題が生じるとプロセスを落とすしかないがSwingだったらアプリが回復するというようなコメントがある。
- JavaFXのGUIコードを書いている時に何度かセグメンテーション違反に遭遇した。

# プロジェクト間違い_問題
何かプログラムに問題があって解決する時、他人のプロジェクトのライブラリやフレームワークに手を加えるべきところで、自分のアプリだけで独自解決してしまう問題。それをプロジェクト間違いと勝手に呼んでみた。どこにコードを書くかを間違えている。

例えばライブラリのコードに問題があるからと独自にリフレクション等を駆使して解決が試みられる場合があるが、大元のプロジェクトへの修正と高速リリースによって解決されるべきだろうと思う。とはいえ、自分のケースだけで解決するよりもより一般的な解決をする方が難しいタスクになる。

XodusやNettyはリリースが早くフィードバックしやすい。
実際にバグ報告をして修正され、すぐに修正版がリリースされた。
高速リリースはライブラリやフレームワークにとって重要だろう。そうしなければ利用者のプロジェクトにおいてリフレクションなどを駆使した特殊なコードが増加していく。

# OS_状況メモ
Windowsを使い続ける理由は既存のソフトウェア資産が豊富だからで、もしバーチャルプラットフォームなソフトウェアが増加するなら、脱Windowsが可能になる。
さらに、私はLinuxデスクトップ等FOSS系OSへの大規模な移行がありうると思っている。Tenyuの相互評価フローネットワークという構想はFOSSを収益化できる可能性があり、もしその構想が実現するならFOSS界隈に大きな変化が起きる。

https://www.wired.com/2015/04/microsoft-open-source-windows-definitely-possible/
Windowsをオープンソースにするという話があるが、そうするくらいならソースコード非公開のまま無料化した方が良い。ソースコードの公開はセキュリティリスクを増大させる懸念があり、非公開の方がFOSS系OSに対する差別化になる。

FOSS系OS
- ソースコード公開
- 無料
- カスタマイズ可能
- ソフトウェアのみ

Windows
- ソースコード非公開
- 有料
- カスタマイズ不可
- ソフトウェアのみ

Mac OS X
- ソースコード非公開
- 有料？ハードウェアとセット
- カスタマイズ不可
- ハードウェアとセット。動作保証しやすい。

その他新しいマイクロカーネルOS。HarmonyOSやFuchsiaなどがある。

FOSS系OSはJDKを標準搭載しJavaアプリをメインに想定する戦略が有力かもしれない。そうする事で全FOSS系OSがアプリ資産を共有できて、FOSS系の弱さであるアプリ資産の乏しさをカバーできる。

# Tenyutalk_案_独自ソフト
Tenyutalkはユーザー中心コンピューティングのための統一的環境を実現する事を目標にしたソフトウェアです。
Tenyu基盤ソフトウェアに統合されていますが、パッケージは基盤と分かれています。
サーバーに人々のコンテンツを集める(=peopleware)のではなく、コンテンツ作者が自分のPCで直接発信します。さらにTenyutalkはP2Pネットワークによる公開日時証明も実装します。

tenyutalkはsmalltalkが示したこれらの思想から影響を受けたものです。
- ユーザー中心コンピューティング
- ネットユーザーの活動を包括的にサポートする統一的システム
- 人間がプログラムと同じものを見る。class browserやinspector

Tenyutalkはネットユーザーが自分のPCでサーバを実行し自分のコンテンツを自ら発信するシステムです。ただし他のノードがコンテンツをキャッシュして代わりに配信するなどしてオフライン時にもコンテンツを提供できたり、大規模なアクセスにも耐えれるようにします。
さらに[Tenyu基盤ソフトウェアのモデルクラス](#Tenyu基盤ソフトウェアのモデルクラス)も重要です。

もともとTenyu基盤ソフトウェアの一部の機能が"セキュリティ要件がほとんどないが高性能なP2P機能"を必要としていて、それを単純に実装するのではなくより汎用的なシステムを実装した結果がTenyutalkです。

さらに**おおむねWWWを代替しうる仕様**を持つ事も要件に入れます。現在それを達成しるうほど実装が進んでいませんが、それを想定した基本設計があります。javaオブジェクトならセマンティックが完全にありmachine redableで、WWWに対して技術的に優位性を持ちえます。

私がこのアイデアを思いついた当初本当に有望なのかを再考したとき思ったのは、これは新しいプログラミング環境の創出であるという事です。このような思想が進んだ先でネット上のあらゆるモデルがmachine readableとなりオープンに共有されている状況を想像できます。

# IPアドレスからレイテンシを予測する
geoip2というIPアドレスから地域を特定するライブラリがあるが、そのようなライブラリが距離計算機能を備えれるはず。
もしその機能があるといくつかのIPアドレスの候補から最も低レイテンシなIPアドレスを選択できるので、P2Pネットワークで効率的な情報拡散ができる。

# Tenyu基盤ソフトウェアのモデルクラス
私はユーザー中心コンピューティングにおいて一貫して通用する抽象的設計の確立に取り組み、Model、IdObject、AdministratedObject等の一列の抽象クラスの系統を設計しました。これらの設計はネット上での人々の活動全般において一貫して適用しうると考えています。

それらモデルクラスを前提としたModelGuiクラスやModelStoreクラスがあります。
ModelGui(一時期ObjectGuiと呼んでいた)クラスはsbfというアイデアがあり、GUIコードの再利用を実現し、従来のWebフロントエンド等と比べて技術的に優れたアイデアです。他のタブと連携したり、モデルに対してただ一度GUIコードを実装すれば様々なGUIからそのコードが再利用されます。



